{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset Transformation + Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Project Dataset Loading"
      ],
      "metadata": {
        "id": "0UnfUwvwN5W6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tL-P3q4MaeG"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "import xml.etree.ElementTree as ET\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the dataset repository from github\n",
        "!git clone https://github.com/leocomelli/score-freetext-answer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQKdp7p4_ZUg",
        "outputId": "7e3bacec-2a84-43f2-f7de-4c7c339d07a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'score-freetext-answer'...\n",
            "remote: Enumerating objects: 511, done.\u001b[K\n",
            "remote: Total 511 (delta 0), reused 0 (delta 0), pack-reused 511\u001b[K\n",
            "Receiving objects: 100% (511/511), 478.34 KiB | 16.49 MiB/s, done.\n",
            "Resolving deltas: 100% (263/263), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_directory = '/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/training/2way/sciEntsBank'\n",
        "test_data_directory = '/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/test/2way/sciEntsBank/test-unseen-answers'"
      ],
      "metadata": {
        "id": "wg4HJSXW_ZXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml_file(xml_file_path):\n",
        "\n",
        "  question = \"\"\n",
        "  ref = \"\"\n",
        "  results = []\n",
        "\n",
        "  for elem in ET.parse(xml_file_path).getroot():\n",
        "    if elem.tag == 'questionText':\n",
        "      question = elem.text\n",
        "    for subelem in elem:\n",
        "      if subelem.tag == 'referenceAnswer':\n",
        "        ref = subelem.text\n",
        "      else:\n",
        "        results.append({\n",
        "            'question': question,\n",
        "            'ref': ref,\n",
        "            'response': subelem.text,\n",
        "            'score': subelem.attrib['accuracy'],\n",
        "            'aug': False\n",
        "        })\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "AFzAxIIbFhVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "test_data = []\n",
        "num_training_questions = 0\n",
        "num_test_questions = 0\n",
        "\n",
        "for data_file in glob.glob(training_data_directory + '/*'):\n",
        "  training_data += parse_xml_file(data_file)\n",
        "  num_training_questions += 1\n",
        "\n",
        "for data_file in glob.glob(test_data_directory + '/*'):\n",
        "  test_data += parse_xml_file(data_file)\n",
        "  num_test_questions += 1\n",
        "\n",
        "print(\"Number of Training Questions:\", num_training_questions)\n",
        "print(\"Number of Training Responses:\", len(training_data))\n",
        "\n",
        "print(\"Number of Test Questions:\", num_test_questions)\n",
        "print(\"Number of Test Responses:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3Cpw_yM_ZaB",
        "outputId": "f8962c91-df81-4e10-d2da-e16aeb9f127e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Questions: 135\n",
            "Number of Training Responses: 4969\n",
            "Number of Test Questions: 46\n",
            "Number of Test Responses: 4562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ShortAnswerGradingDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Note: I handle the parsing in the data loading from XML section\n",
        "        # Returns a dict for each item with the following keys: 'question', 'ref', 'response', 'score' all of type 'str'\n",
        "        return self.dataset[idx]"
      ],
      "metadata": {
        "id": "GE1wyg4kAUwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = ShortAnswerGradingDataset(training_data)\n",
        "test_dataset = ShortAnswerGradingDataset(test_data)"
      ],
      "metadata": {
        "id": "MHkQGLsLEalY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batching and Loading Data to Model\n",
        "\n",
        "Use this iterator to load in the train and test datasets to the model of choice."
      ],
      "metadata": {
        "id": "5ds1t-pzQJ3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "limit = 10\n",
        "for training_item in training_dataset:\n",
        "  print(training_item)\n",
        "  if limit == 0:\n",
        "    break\n",
        "  limit -= 1\n",
        "\n",
        "limit = 10\n",
        "for test_item in test_dataset:\n",
        "  print(test_item)\n",
        "  if limit == 0:\n",
        "    break\n",
        "  limit -= 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhEub_c-T6cv",
        "outputId": "c1dffed9-aaed-4851-9a2e-ff98e88bb76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'One is a loop and one is arch.', 'score': 'incorrect', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are the same.', 'score': 'incorrect', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'The both finer patterns are loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are same loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are both loops.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'Because you look at the finger patterns.', 'score': 'incorrect', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'They are both a loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'Look at the finger patterns below, then answer the questions. What is the same about the finger patterns?', 'ref': 'Both finger patterns are loops.', 'response': 'Loop.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I know the paperclip would scratch it because a paperclip is harder than a penny.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I knew that because the paperclip is harder than the penny.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I know that the paperclip would scratch the mineral because a paperclip is harder than a penny.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'Because the paperclip is an easier item to scratch a rock or mineral than a penny.', 'score': 'incorrect', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I know that a paperclip will scratch it because it is the hardest tool that we used out of a fingernail, penny and paperclip.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I know because the paperclip is a harder tool so if a softer tool can scratch it so can the paperclip.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'The paperclip can scratch the penny and the penny cannot scratch the paperclip so the paperclip is harder.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'You can scratch the penny with the paperclip so the penny is softer and if the penny could scratch the paperclip can scratch it.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'A paperclip is harder because we scratched the penny with the paperclip. The penny got a scratch.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I know because a paperclip is harder than the penny. I figured that out by scratching the penny with the paperclip and it was harder.', 'score': 'correct', 'aug': False}\n",
            "{'question': 'You used 3 scratch tools in class to test minerals for hardness: your fingernail, a penny, and a paperclip. If a mineral can be scratched by a penny, you can be sure that a (paperclip) will also scratch it. Explain how you know that tool would scratch the mineral.', 'ref': 'A paperclip is harder than a penny, so if a penny can scratch a mineral, a paperclip can also scratch the mineral.', 'response': 'I know because a penny is softer than a paperclip.', 'score': 'correct', 'aug': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Augmentation\n",
        "\n",
        "Using Google Translate, we can augment the relatively small amount of training data via Backtranslation."
      ],
      "metadata": {
        "id": "jItRfPfSzKSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q googletrans==3.1.0a0"
      ],
      "metadata": {
        "id": "TEclZ4HD0DXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import googletrans\n",
        "from googletrans import Translator\n",
        "import json"
      ],
      "metadata": {
        "id": "eVHePTdtzKbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question Response Map Creation\n",
        "\n",
        "We create this to ensure that any generated responses do not match any of the existing responses for the question. This prevents duplication and improves the quality of the dataset."
      ],
      "metadata": {
        "id": "MSrXWU1h8goJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_response_map = {}\n",
        "\n",
        "for training_item in training_dataset:\n",
        "  question = training_item['question']\n",
        "\n",
        "  if question not in question_response_map:\n",
        "    question_response_map[question] = set()\n",
        "\n",
        "  response = training_item['response']\n",
        "  question_response_map[question].add(response)"
      ],
      "metadata": {
        "id": "ZtWJYGdK79XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Translation Functions\n",
        "\n",
        "These methods will perform the augmentation of the dataset via backtranslation."
      ],
      "metadata": {
        "id": "a1EMgR7A8rbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()"
      ],
      "metadata": {
        "id": "99GkLybl8xtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backtranslate_example(input_item):\n",
        "  original_response = input_item['response']\n",
        "  tr1 = translator.translate(original_response, src='en', dest='es').text\n",
        "  new_response = translator.translate(tr1, src='es', dest='en').text\n",
        "\n",
        "  # Do not add the new response if it is the same after translation\n",
        "  if new_response == original_response:\n",
        "    return None\n",
        "\n",
        "  # Do not add the new response if there is already another response that is the same\n",
        "  if new_response in question_response_map[input_item['question']]:\n",
        "    return None\n",
        "\n",
        "  # Update the question response map with the new response\n",
        "  question_response_map[input_item['question']].add(new_response)\n",
        "\n",
        "  # Create a new dataset entry and return it\n",
        "  new_dataset_entry = {\n",
        "    'question': input_item['question'],\n",
        "    'ref': input_item['ref'],\n",
        "    'response': new_response,\n",
        "    'score': input_item['score'],\n",
        "    'aug': True\n",
        "  }\n",
        "\n",
        "  return new_dataset_entry"
      ],
      "metadata": {
        "id": "inPxbN120P9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_generation(starting_idx, limit):\n",
        "  gen_list = []\n",
        "  for idx, training_item in enumerate(training_dataset):\n",
        "    if idx < starting_idx:\n",
        "      continue\n",
        "\n",
        "    augmented_item = backtranslate_example(training_item)\n",
        "    if augmented_item:\n",
        "      gen_list.append(augmented_item)\n",
        "\n",
        "    if idx % 100 == 0:\n",
        "      print('Processed', idx)\n",
        "\n",
        "    if idx == starting_idx + limit:\n",
        "      print('Finished Processing To Index', idx)\n",
        "      return gen_list\n",
        "  print('Finished Processing All Data')\n",
        "  return gen_list"
      ],
      "metadata": {
        "id": "peUmKlkvzVuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Augmentation Implementation\n",
        "\n",
        "Note that we break these into multiple cells. This is due to the rate limiting with the translate method, and it benefits from having each cell called individually with down-time in between cell executions."
      ],
      "metadata": {
        "id": "UWY9Z0Nr5K3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data = []"
      ],
      "metadata": {
        "id": "G-Qr_cT25JsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data += process_generation(0, 999)\n",
        "print('Size of Augmented Dataset', len(augmented_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TStSX4Mz38UP",
        "outputId": "3ea2f30d-370f-48cf-fa5a-0876141cb884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0\n",
            "Processed 100\n",
            "Processed 200\n",
            "Processed 300\n",
            "Processed 400\n",
            "Processed 500\n",
            "Processed 600\n",
            "Processed 700\n",
            "Processed 800\n",
            "Processed 900\n",
            "Finished Processing To Index 999\n",
            "Size of Augmented Dataset 790\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data += process_generation(1000, 999)\n",
        "print('Size of Augmented Dataset', len(augmented_data)) # Size of Augmented Dataset 1647"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cgy5p1rW4z3Q",
        "outputId": "a42193e6-b81c-48f7-d255-074e7399ed16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1000\n",
            "Processed 1100\n",
            "Processed 1200\n",
            "Processed 1300\n",
            "Processed 1400\n",
            "Processed 1500\n",
            "Processed 1600\n",
            "Processed 1700\n",
            "Processed 1800\n",
            "Processed 1900\n",
            "Finished Processing To Index 1999\n",
            "Size of Augmented Dataset 1614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data += process_generation(2000, 999)\n",
        "print('Size of Augmented Dataset', len(augmented_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JUsFCMl5E2d",
        "outputId": "0c841d11-b351-4dd3-faa9-e5bea3642922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 2000\n",
            "Processed 2100\n",
            "Processed 2200\n",
            "Processed 2300\n",
            "Processed 2400\n",
            "Processed 2500\n",
            "Processed 2600\n",
            "Processed 2700\n",
            "Processed 2800\n",
            "Processed 2900\n",
            "Finished Processing To Index 2999\n",
            "Size of Augmented Dataset 2406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data += process_generation(3000, 999)\n",
        "print('Size of Augmented Dataset', len(augmented_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJANgK-o5Fia",
        "outputId": "a309ff64-f781-4055-f52e-d1ce56baf38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 3000\n",
            "Processed 3100\n",
            "Processed 3200\n",
            "Processed 3300\n",
            "Processed 3400\n",
            "Processed 3500\n",
            "Processed 3600\n",
            "Processed 3700\n",
            "Processed 3800\n",
            "Processed 3900\n",
            "Finished Processing To Index 3999\n",
            "Size of Augmented Dataset 3186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data += process_generation(4000, 999) \n",
        "print('Size of Augmented Dataset', len(augmented_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f87b8pPX5GeA",
        "outputId": "b9b5f685-0589-409c-a4e9-bb2d9ed22f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 4000\n",
            "Processed 4100\n",
            "Processed 4200\n",
            "Processed 4300\n",
            "Processed 4400\n",
            "Processed 4500\n",
            "Processed 4600\n",
            "Processed 4700\n",
            "Processed 4800\n",
            "Processed 4900\n",
            "Finished Processing All Data\n",
            "Size of Augmented Dataset 3932\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Size of Original  Dataset', len(training_data))\n",
        "\n",
        "print('Size of Combined  Dataset', len(training_data) + len(augmented_data))\n",
        "\n",
        "print(f'Dataset Size Increase {100*len(augmented_data)/len(training_data)}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udkCFBMg11vz",
        "outputId": "4a892462-b6e0-4014-9779-8d8e79e43fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Original  Dataset 4969\n",
            "Size of Combined  Dataset 8901\n",
            "Dataset Size Increase 79.13060978063997%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results\n",
        "\n",
        "We have increased the size of our training set by almost 80%! This is a big improve that we hope will lead to better results in model training and fine-tuning.\n",
        "\n",
        "Now, save all of the files as .json for easier use in the future"
      ],
      "metadata": {
        "id": "C-zgIXxzELjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save augmented training data\n",
        "with open('/content/train.json', 'w') as fp:\n",
        "    json.dump(augmented_data + training_data, fp)"
      ],
      "metadata": {
        "id": "7IPN7ZDXBK5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_unseen_questions = ('/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/test/2way/sciEntsBank/test-unseen-questions', 'questions')\n",
        "test_unseen_answers = ('/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/test/2way/sciEntsBank/test-unseen-answers', 'answers')\n",
        "test_unseen_domains = ('/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/test/2way/sciEntsBank/test-unseen-domains', 'domains')"
      ],
      "metadata": {
        "id": "hI5GblNcEYmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_set_tuple in [test_unseen_domains, test_unseen_answers, test_unseen_questions]:\n",
        "  curr_test_data = []\n",
        "  for data_file in glob.glob(test_set_tuple[0] + '/*'):\n",
        "    curr_test_data += parse_xml_file(data_file)\n",
        "\n",
        "  with open(f'/content/test-unseen-{test_set_tuple[1]}.json', 'w') as fp:\n",
        "    json.dump(curr_test_data, fp)\n",
        "  \n",
        "  print('Saved Test Set Unseen', test_set_tuple[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-n1zW0lEYvs",
        "outputId": "7e2e2cf5-8dc2-4ad3-ad80-19d1900c8140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Test Set Unseen domains\n",
            "Saved Test Set Unseen answers\n",
            "Saved Test Set Unseen questions\n"
          ]
        }
      ]
    }
  ]
}