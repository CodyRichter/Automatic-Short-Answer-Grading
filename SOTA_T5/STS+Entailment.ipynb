{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "STS+Entailment.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZUv6xea2Sy0",
        "outputId": "53fd5727-445d-49d9-94a3-df8fb7a4f2a8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get the dataset"
      ],
      "metadata": {
        "id": "X97m8WImzT9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import glob\n",
        "import numpy as np\n",
        "import json"
      ],
      "metadata": {
        "id": "-WvB20vO2elM"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the dataset repository from github\n",
        "!git clone https://github.com/leocomelli/score-freetext-answer.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHHW7C8K-Xxr",
        "outputId": "989a094e-4cac-4f56-97a2-4f3b6db46102"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'score-freetext-answer' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import Trainer, TrainingArguments, BertForSequenceClassification, BertTokenizer, BertModel, AutoModel, AutoTokenizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "lHrR16T-92gq"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_directory = '/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/training/2way/sciEntsBank'\n",
        "test_data_directory = '/content/score-freetext-answer/src/main/resources/corpus/semeval2013-task7/test/2way/sciEntsBank/test-unseen-answers'"
      ],
      "metadata": {
        "id": "TBLx5w5H6R6w"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml_file(xml_file_path):\n",
        "\n",
        "  question = \"\"\n",
        "  ref = \"\"\n",
        "  results = []\n",
        "\n",
        "  for elem in ET.parse(xml_file_path).getroot():\n",
        "    if elem.tag == 'questionText':\n",
        "      question = elem.text\n",
        "    for subelem in elem:\n",
        "      if subelem.tag == 'referenceAnswer':\n",
        "        ref = subelem.text\n",
        "      else:\n",
        "        results.append({\n",
        "            'question': question,\n",
        "            'ref': ref,\n",
        "            'response': subelem.text,\n",
        "            'score': subelem.attrib['accuracy']\n",
        "        })\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "Tj9O9GnY9c0k"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_raw = []\n",
        "test_data_raw = []\n",
        "num_training_questions = 0\n",
        "num_test_questions = 0\n",
        "\n",
        "for data_file in glob.glob(training_data_directory + '/*'):\n",
        "  training_data_raw += parse_xml_file(data_file)\n",
        "  num_training_questions += 1\n",
        "\n",
        "for data_file in glob.glob(test_data_directory + '/*'):\n",
        "  test_data_raw += parse_xml_file(data_file)\n",
        "  num_test_questions += 1\n",
        "\n",
        "print(\"Number of Training Questions:\", num_training_questions)\n",
        "print(\"Number of Training Responses:\", len(training_data_raw))\n",
        "\n",
        "print(\"Number of Test Questions:\", num_test_questions)\n",
        "print(\"Number of Test Responses:\", len(test_data_raw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FczHEbJy9gl-",
        "outputId": "7c4b2db6-4011-4d15-c3a5-78e1fd7ef925"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Questions: 135\n",
            "Number of Training Responses: 4969\n",
            "Number of Test Questions: 135\n",
            "Number of Test Responses: 540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concate the reference answer and student answer to create new input for both train and test set\n",
        "texts_reference_untokenized = []\n",
        "texts_response_untokenized = []\n",
        "data_scores_numeric = []\n",
        "\n",
        "maxl = []\n",
        "for training_item in training_data_raw:    \n",
        "  texts_reference_untokenized.append(training_item['ref'])\n",
        "  texts_response_untokenized.append(training_item['response'])\n",
        "  data_scores_numeric.append(0 if training_item[\"score\"] == 'incorrect' else 1)\n",
        "\n",
        "for test_item in test_data_raw:\n",
        "  texts_reference_untokenized.append(test_item['ref'])\n",
        "  texts_response_untokenized.append(test_item['response'])\n",
        "  data_scores_numeric.append(0 if test_item[\"score\"] == 'incorrect' else 1)\n",
        "\n",
        "texts_reference_untokenized = np.asarray(texts_reference_untokenized)\n",
        "texts_response_untokenized = np.asarray(texts_response_untokenized)\n",
        "data_scores_numeric = np.asarray(data_scores_numeric)"
      ],
      "metadata": {
        "id": "y2XEfgPA9mnj"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(texts_reference_untokenized))\n",
        "print(len(texts_response_untokenized))\n",
        "print(texts_reference_untokenized[0])\n",
        "print(texts_response_untokenized[0])\n",
        "print(data_scores_numeric[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmDD1zZA9uXT",
        "outputId": "9d37d09c-0776-469b-bbf0-cab0ece52f84"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5509\n",
            "5509\n",
            "Agree. Vibrations are movements. Vibrations produce sound.\n",
            "Yes, Because if things do not move it will not make a sound. Like if you are talking your voice box has to move.\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"mnli premise: \" + texts_response_untokenized[0] + \" hypothesis: \" + texts_reference_untokenized[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA6A7xHR-y7Z",
        "outputId": "6e06fcdf-4bc9-499c-e95d-22e88fea9fdb"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mnli premise: Yes, Because if things do not move it will not make a sound. Like if you are talking your voice box has to move. hypothesis: Agree. Vibrations are movements. Vibrations produce sound.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Batch Inference"
      ],
      "metadata": {
        "id": "wbYUdvp1zfJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch the inputs\n",
        "\n",
        "\n",
        "# input_ids = \"mnli premise: \" + training_data_raw[5]['question'] + \" hypothesis: \" + training_data_raw[5]['response']\n",
        "# one = tokenizer([\"mnli premise: \" + training_data_raw[0]['question'] + \" hypothesis: \" + training_data_raw[0]['response'], \"mnli premise: \" + training_data_raw[1]['question'] + \" hypothesis: \" + training_data_raw[1]['response'], input_ids], return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "\n",
        "\n",
        "# outputs = model.generate(one)\n",
        "# print(outputs)\n",
        "# for i in range(len(outputs)):\n",
        "#   res = tokenizer.decode(outputs[i], skip_special_tokens=True)\n",
        "#   print(res)"
      ],
      "metadata": {
        "id": "d0QaLSKVgeQ8"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def batch_inputs_mnli(train_data):\n",
        "#   input_sequences = []\n",
        "#   for item in train_data:\n",
        "#     input_sequences.append(\"mnli premise: \" + item['question'] + \" hypothesis: \" + item['response'])\n",
        "#   return input_sequences"
      ],
      "metadata": {
        "id": "EEiaoyHbge9e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_sequences = batch_inputs_mnli(training_data_raw)\n",
        "# input_sequences[:5]"
      ],
      "metadata": {
        "id": "TWQTIqQii4jw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 Model"
      ],
      "metadata": {
        "id": "J6CMpYKdzm3O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lr6XcQ52FU6",
        "outputId": "a36ef0c1-434e-4a67-8b5c-ee9bbfdf502b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0\n"
          ]
        }
      ],
      "source": [
        "# Vanilla T5-small\n",
        "\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
        "\n",
        "input_ids = tokenizer(\"stsb sentence1: The house is wonderful. sentence2: This house is great\", return_tensors=\"pt\").input_ids\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Free the memory\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# Time the inference\n",
        "\n",
        "import time\n",
        "\n",
        "start_time = time.clock()\n",
        "input_ids = tokenizer(input_sequences[0], return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "outputs = model.generate(input_ids)\n",
        "res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(time.clock() - start_time, \"seconds\")\n",
        "print((time.clock() - start_time) * len(training_data_raw) / 60, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KUeB0_mqgT1",
        "outputId": "cc4ab5bf-645a-47ec-a6aa-433b2d059711"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "367"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 inference on the Training Data: Textual \n",
        "##### Note: takes a long time to run."
      ],
      "metadata": {
        "id": "rfJHhyqvz43z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "entailment = 0\n",
        "contra_neutral = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "# batch_size = 64\n",
        "for idx, training_item in enumerate(training_data_raw):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"mnli premise: \" + training_item['ref'] + \" hypothesis: \" + training_item['response'], return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  training_item[\"mnli\"] = res\n",
        "  if res == \"entailment\":\n",
        "    entailment += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  if res != \"entailment\":\n",
        "    contra_neutral += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "  \n"
      ],
      "metadata": {
        "id": "cVKjCHFL98ak"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(true_pos, false_pos, true_neg, false_neg, entailment, contra_neutral)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwxKKIgM2EJs",
        "outputId": "d2d7d3cb-a1ae-4ecc-beee-a15b6223a3e2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1157 1182 1779 851 2339 2630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", (true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKsgoVpD2ESd",
        "outputId": "13b4933a-80a2-4a74-9636-76de8760590b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5908633527872812"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 inference on the Training Data: Sentence Similarity\n",
        "##### Note: takes a long time to run"
      ],
      "metadata": {
        "id": "qt5vniEH0wr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "for idx, training_item in enumerate(training_data_raw):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"stsb sentence1: \" + training_item['ref'] + \" sentence2: \" + training_item['response'], return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  training_item[\"sts\"] = res\n",
        "\n",
        "  if float(res) > 2.5:\n",
        "    pred_true += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "  \n"
      ],
      "metadata": {
        "id": "PYoBTlf8KmSK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: \", (true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lso5U-I-KmU7",
        "outputId": "1a80f699-0ff2-4a97-c00c-42ae9ac2dd00"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6081706580800966"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error Analysis"
      ],
      "metadata": {
        "id": "0GD3gOL91FFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wZi1qdNMAJ14"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_pd = pd.DataFrame(training_data_raw)\n",
        "results = train_data_pd[[\"score\", \"mnli\", \"sts\"]]"
      ],
      "metadata": {
        "id": "UyYNGnFfKmc0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "wMHs-Wq5BuIY",
        "outputId": "78e16a22-242d-40b8-cbcd-c8551cc39f0a"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          score           mnli  sts\n",
              "0     incorrect  contradiction  2.4\n",
              "1     incorrect  contradiction  2.2\n",
              "2     incorrect     entailment  0.4\n",
              "3       correct     entailment  3.6\n",
              "4       correct     entailment  3.6\n",
              "...         ...            ...  ...\n",
              "4964  incorrect  contradiction  2.8\n",
              "4965  incorrect  contradiction  0.8\n",
              "4966  incorrect  contradiction  0.0\n",
              "4967  incorrect     entailment  2.8\n",
              "4968  incorrect  contradiction  2.8\n",
              "\n",
              "[4969 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1595a968-5ed6-49da-91a4-245e840aeb53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>mnli</th>\n",
              "      <th>sts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>correct</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>correct</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4964</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4965</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4966</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4967</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4968</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>2.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4969 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1595a968-5ed6-49da-91a4-245e840aeb53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1595a968-5ed6-49da-91a4-245e840aeb53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1595a968-5ed6-49da-91a4-245e840aeb53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Agreement\n",
        "agree = 0\n",
        "for index, row in results.iterrows():\n",
        "  if row[\"mnli\"] == \"entailment\" and float(row[\"sts\"]) > 2.5:\n",
        "    agree +=1\n",
        "agree / len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93RafNw4Kmfe",
        "outputId": "a0f4850c-a750-477b-a148-7b8cb57ccad5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30307909036023345"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Break ties\n",
        "\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "_7ejSIjsKmiC"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logical OR\n",
        "for index, row in results.iterrows():\n",
        "\n",
        "  if float(row[\"sts\"]) > 2.5 or row[\"mnli\"] == \"entailment\":\n",
        "    pred_true += 1\n",
        "    if row[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if row[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1"
      ],
      "metadata": {
        "id": "0le2HtHKDGEg"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgtaQ5yPKmkh",
        "outputId": "6f7aa3ab-b8d1-46bc-bdf0-ccf0aebc9e1f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5995170054336889"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logical AND\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "\n",
        "\n",
        "for index, row in results.iterrows():\n",
        "\n",
        "  if float(row[\"sts\"]) > 2.5 and row[\"mnli\"] == \"entailment\":\n",
        "    pred_true += 1\n",
        "    if row[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if row[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1"
      ],
      "metadata": {
        "id": "7Jbz3KsMKmm6"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O5j0rv0Kmpn",
        "outputId": "ffc58a18-f156-427e-c895-1b9024fdb5d0"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6333266250754679"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 Inference on Test Data (Unseen Answers):"
      ],
      "metadata": {
        "id": "2TMNz1aY1W3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "entailment = 0\n",
        "contra_neutral = 0\n",
        "op = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "batch_size = 64\n",
        "for idx, training_item in enumerate(test_data_raw):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"mnli premise: \" + training_item['ref'] + \" hypothesis: \" + training_item['response'], return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  training_item[\"mnli\"] = res\n",
        "  if res == \"entailment\":\n",
        "    entailment += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  if res != \"entailment\":\n",
        "    contra_neutral += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "\n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "id": "RU7nxDFuD3IS"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9YlFSMqD3K2",
        "outputId": "bdd347f2-c915-460d-c098-5d100fb79185"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6240740740740741"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "for idx, training_item in enumerate(test_data_raw):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"stsb sentence1: \" + training_item['ref'] + \" sentence2: \" + training_item['response'], return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  training_item[\"sts\"] = res\n",
        "\n",
        "  if float(res) > 2.5:\n",
        "    pred_true += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "  \n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox4aBvp1HS47",
        "outputId": "7780f929-f158-42b7-ff76-a74d8bd6d0dd"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6648148148148149"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_pd = pd.DataFrame(test_data_raw)\n",
        "results_test = train_data_pd[[\"score\", \"mnli\", \"sts\"]]"
      ],
      "metadata": {
        "id": "30eXeP43HTBq"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Agreement\n",
        "agree = 0\n",
        "for index, row in results_test.iterrows():\n",
        "  if row[\"mnli\"] == \"entailment\" and float(row[\"sts\"]) > 2.5:\n",
        "    agree +=1\n",
        "agree / len(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijVHMGakHTEL",
        "outputId": "27bb0671-850f-40bd-c509-835847562b6b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.30307909036023345"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logical AND\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "\n",
        "\n",
        "for index, row in results_test.iterrows():\n",
        "\n",
        "  if float(row[\"sts\"]) > 2.5 and row[\"mnli\"] == \"entailment\":\n",
        "    pred_true += 1\n",
        "    if row[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if row[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "\n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRQEIEXMHTG2",
        "outputId": "218b8b37-e38a-4bc0-b731-5a359fdfc0b0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6333266250754679"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "for idx, training_item in enumerate(test_data_raw):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"stsb sentence1: \" + training_item['ref'] + \" sentence2: \" + training_item['response'], padding=True, truncation=True, return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  sentence_embeddings = mean_pooling(outputs, encoded_input['attention_mask'])\n",
        "  res = tokenizer.decode(sentence_embeddings, skip_special_tokens=True)\n",
        "  training_item[\"sts\"] = res\n",
        "  if idx == 20:\n",
        "    break\n",
        "  if float(res) > 2.5:\n",
        "    pred_true += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "  \n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "eYyV2U84gvZd",
        "outputId": "1e395164-f368-4037-f054-c1f0916df9aa"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Input length of input_ids is 34, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-3d2d003e5759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;31m# print(training_item)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stsb sentence1: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ref'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" sentence2: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_item\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0msentence_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m                 \u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict_in_generate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m                 \u001b[0msynced_gpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynced_gpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             )\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgreedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1647\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# don't waste resources running the code we don't need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1649\u001b[0;31m             \u001b[0mnext_token_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0;31m# Store scores, attentions and hidden_states when required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'logits'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T5 Inference on Test Data (Unseen Questions):"
      ],
      "metadata": {
        "id": "W627rS4F1s5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the dataset repository from github\n",
        "!git clone https://github.com/CodyRichter/Automatic-Short-Answer-Grading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82bLJQmOhhmd",
        "outputId": "e6e90f13-9f0a-4db6-a381-b77f6561a145"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Automatic-Short-Answer-Grading'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 33 (delta 12), reused 23 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/Automatic-Short-Answer-Grading/dataset/train.json', 'r') as tf:\n",
        "  training_data = json.load(tf)\n",
        "\n",
        "with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-answers.json', 'r') as tf:\n",
        "  test_unseen_answer_data = json.load(tf)\n",
        "\n",
        "with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-questions.json', 'r') as tf:\n",
        "  test_unseen_question_data = json.load(tf)\n",
        "\n",
        "with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-domains.json', 'r') as tf:\n",
        "  test_unseen_domain_data = json.load(tf)\n",
        "\n",
        "print('Number of Training + Validation Data Responses', len(training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzgst-Peof21",
        "outputId": "0c742278-0a85-4649-92e1-11d6ef500179"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training + Validation Data Responses 16265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class ShortAnswerGradingDataset(Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Note: I handle the parsing in the data loading from XML section\n",
        "        # Returns a dict for each item with the following keys: 'question', 'ref', 'response', 'score' all of type 'str'\n",
        "        return self.dataset[idx]"
      ],
      "metadata": {
        "id": "1QdnGigNohws"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dataset = ShortAnswerGradingDataset(training_data)\n",
        "test_dataset_unseen_answers = ShortAnswerGradingDataset(test_unseen_answer_data)\n",
        "test_dataset_unseen_questions = ShortAnswerGradingDataset(test_unseen_question_data)\n",
        "test_dataset_unseen_domains = ShortAnswerGradingDataset(test_unseen_domain_data)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_dataset, validation_dataset = train_test_split(training_dataset, test_size=0.1, random_state=0)\n",
        "\n",
        "validation_parent_ids = set()\n",
        "validation_ids_to_remove = set()\n",
        "validation_original_ids = set()\n",
        "\n",
        "# Step 1: Get IDs of Original Responses and mark augmented ones for deletion\n",
        "for validation_item in validation_dataset:\n",
        "  if validation_item['aug']:\n",
        "    validation_parent_ids.add(validation_item['aug_metadata']['parent_id'])\n",
        "    validation_ids_to_remove.add(validation_item['id'])\n",
        "  else:\n",
        "    validation_original_ids.add(validation_item['id'])\n",
        "\n",
        "train_ids_to_remove = set()\n",
        "\n",
        "# Step 2: Obtain Original Respones for validation set and mark augmented\n",
        "#         dataset items for removal if the original is in the validation set\n",
        "for train_item in training_dataset:\n",
        "\n",
        "  # If the original is in the validation set, remove from the training set\n",
        "  if train_item['aug'] and train_item['aug_metadata']['parent_id'] in validation_original_ids:\n",
        "    train_ids_to_remove.add(train_item['id'])\n",
        "\n",
        "  # If the original is in the training set, add it to the validation set\n",
        "  # and then mark it for deletion from the training set\n",
        "  if not train_item['aug'] and train_item['id'] in validation_parent_ids:\n",
        "    validation_dataset.append(train_item)\n",
        "    train_ids_to_remove.add(train_item['id'])\n",
        "\n",
        "# Step 3: Perform removal operations\n",
        "validation_dataset[:] = [x for x in validation_dataset if x['id'] not in validation_ids_to_remove]\n",
        "training_dataset[:] = [x for x in training_dataset if x['id'] not in train_ids_to_remove]"
      ],
      "metadata": {
        "id": "EEqyjjWOojh5"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of Training Samples', len(training_dataset))\n",
        "print('Number of Validation Samples', len(validation_dataset))\n",
        "print('Number of Test Data (New Answer) Responses', len(test_unseen_answer_data))\n",
        "print('Number of Test Data (New Question) Responses', len(test_unseen_question_data))\n",
        "print('Number of Test Data (New Domain) Responses', len(test_unseen_domain_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "El0SKnOeole5",
        "outputId": "8c2a308d-5cb4-465b-c274-eead041b8f42"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Training Samples 12805\n",
            "Number of Validation Samples 1380\n",
            "Number of Test Data (New Answer) Responses 540\n",
            "Number of Test Data (New Question) Responses 733\n",
            "Number of Test Data (New Domain) Responses 4562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "for idx, training_item in enumerate(test_unseen_question_data):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"stsb sentence1: \" + training_item['ref'] + \" sentence2: \" + training_item['response'], return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  training_item[\"sts\"] = res\n",
        "\n",
        "  if float(res) > 2.5:\n",
        "    pred_true += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    pred_false += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "  \n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuenHtEsonJW",
        "outputId": "008daae1-0c2f-47d6-f8b0-010c798823db"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6575716234652115"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO Paralellize\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "entailment = 0\n",
        "contra_neutral = 0\n",
        "op = 0\n",
        "# input_ids = tokenizer(input_sequences, return_tensors=\"pt\", padding=True, truncation=True).input_ids\n",
        "# outputs = model.generate(input_ids)\n",
        "batch_size = 64\n",
        "for idx, training_item in enumerate(test_unseen_question_data):\n",
        "  # print(training_item)\n",
        "  input_ids = tokenizer(\"mnli premise: \" + training_item['ref'] + \" hypothesis: \" + training_item['response'], return_tensors=\"pt\").input_ids\n",
        "  outputs = model.generate(input_ids)\n",
        "  res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "  training_item[\"mnli\"] = res\n",
        "  if res == \"entailment\":\n",
        "    entailment += 1\n",
        "    if training_item[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  if res != \"entailment\":\n",
        "    contra_neutral += 1\n",
        "    if training_item[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "\n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32vba5iko1TS",
        "outputId": "04919f0a-ba2f-4635-ee99-5b35832bc00d"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6125511596180082"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_unseen_data_pd = pd.DataFrame(test_unseen_question_data)\n",
        "results_test_unseen = test_unseen_data_pd[[\"score\", \"mnli\", \"sts\"]]"
      ],
      "metadata": {
        "id": "-GikI_TCpVxL"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Result: State-of-the-art 68.89% for zero-shot methods.\n",
        "##### 71%, 75% state-of-the-art published in 2017, 2018 using handcrafted features and full training."
      ],
      "metadata": {
        "id": "cWd-Q2Xx13T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logical AND\n",
        "true_pos = 0\n",
        "false_pos = 0\n",
        "true_neg = 0\n",
        "false_neg = 0\n",
        "pred_true = 0\n",
        "pred_false = 0\n",
        "mnli_AND_sts = []\n",
        "\n",
        "for index, row in results_test_unseen.iterrows():\n",
        "\n",
        "  if float(row[\"sts\"]) > 3.0 and row[\"mnli\"] == \"entailment\":\n",
        "    mnli_AND_sts.append(1)\n",
        "    pred_true += 1\n",
        "    if row[\"score\"] == \"correct\":\n",
        "      true_pos+=1\n",
        "    else:\n",
        "      false_pos += 1\n",
        "  else:\n",
        "    mnli_AND_sts.append(0)\n",
        "    pred_false += 1\n",
        "    if row[\"score\"] == \"incorrect\":\n",
        "      true_neg+=1\n",
        "    else:\n",
        "      false_neg+=1\n",
        "\n",
        "(true_pos + true_neg) / (true_pos+ false_pos+ true_neg+ false_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6YDRd_vp40w",
        "outputId": "ecfeabbe-2c6b-4319-fd34-a5772371e2fc"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6889495225102319"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Computing other metrics. (Not reported in the paper)"
      ],
      "metadata": {
        "id": "BUK6b4r22PPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_test_unseen[\"mnli_AND_sts\"] = mnli_AND_sts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ckG2Su0WoO",
        "outputId": "9e21cbdc-ecb4-481c-e817-23bcd9bd5519"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_test_unseen[\"score_number\"] = results_test_unseen[\"score\"].apply(lambda x: 1 if x==\"correct\" else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_tPTy5v1K-K",
        "outputId": "a3c7abff-bc5f-44f3-dee5-b1f81f0246f2"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_test_unseen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "XGi4f54l0NHH",
        "outputId": "d6742886-a0b3-4d2a-801b-2b258ccc4d0d"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         score           mnli  sts  mnli_AND_sts  score_number\n",
              "0    incorrect     entailment  3.6             1             0\n",
              "1    incorrect     entailment  0.0             0             0\n",
              "2    incorrect     entailment  0.0             0             0\n",
              "3    incorrect     entailment  0.0             0             0\n",
              "4    incorrect     entailment  0.0             0             0\n",
              "..         ...            ...  ...           ...           ...\n",
              "728    correct     entailment  4.0             1             1\n",
              "729    correct     entailment  4.0             1             1\n",
              "730    correct     entailment  2.4             0             1\n",
              "731  incorrect  contradiction  0.0             0             0\n",
              "732  incorrect     entailment  0.8             0             0\n",
              "\n",
              "[733 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f08e26f-95b8-4289-bd0a-d3875605f59a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>mnli</th>\n",
              "      <th>sts</th>\n",
              "      <th>mnli_AND_sts</th>\n",
              "      <th>score_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>correct</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>729</th>\n",
              "      <td>correct</td>\n",
              "      <td>entailment</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>correct</td>\n",
              "      <td>entailment</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>731</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>contradiction</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>732</th>\n",
              "      <td>incorrect</td>\n",
              "      <td>entailment</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>733 rows Ã— 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f08e26f-95b8-4289-bd0a-d3875605f59a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f08e26f-95b8-4289-bd0a-d3875605f59a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f08e26f-95b8-4289-bd0a-d3875605f59a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        " \n",
        " \n",
        "# Apply the pearsonr()\n",
        "corr, _ = pearsonr(results_test_unseen[\"mnli_AND_sts\"], results_test_unseen[\"score_number\"])\n",
        "print('Pearsons correlation: %.3f' % corr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_JTHCPtp43F",
        "outputId": "97730f1c-c5ab-4df1-8327-20c4385250b6"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearsons correlation: 0.351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mean_squared_error(results_test_unseen[\"score_number\"], results_test_unseen[\"mnli_AND_sts\"], squared=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcQ2X_Bf2SrW",
        "outputId": "d6a4a3ba-a7b4-4c8d-ca43-d54589b166bf"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5577189950949923"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used the training datast to find the threshold\n",
        "stack models\n",
        "use combination score"
      ],
      "metadata": {
        "id": "qFxFbvBFsDTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(results_test_unseen[\"score_number\"], results_test_unseen[\"mnli_AND_sts\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "gr3eZrfkp45M",
        "outputId": "c7d130d0-0763-4c0f-fa34-7cb2d9ad8bbf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7e7bb28136e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_test_unseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"score_number\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_test_unseen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mnli_AND_sts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results_test_unseen' is not defined"
          ]
        }
      ]
    }
  ]
}