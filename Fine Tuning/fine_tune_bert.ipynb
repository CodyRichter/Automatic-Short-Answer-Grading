{"cells":[{"cell_type":"markdown","metadata":{"id":"pvdhFnb44b4J"},"source":["https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb#scrollTo=xtkcmIY9t6AF"]},{"cell_type":"markdown","metadata":{"id":"YIv7rF4V6lyE"},"source":["## Installation of libraries and imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15787,"status":"ok","timestamp":1651937115829,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"42-lJ1u9IHT6","outputId":"9232ae55-4247-46be-f708-463a9b01a128"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.53)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"KE_TpNaSZQ5n","executionInfo":{"status":"ok","timestamp":1651937125138,"user_tz":240,"elapsed":7406,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import os\n","import matplotlib.pyplot as plt\n","import copy\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import pandas as pd\n","import glob\n","import xml.etree.ElementTree as ET\n","from torch.utils.data import DataLoader, Dataset\n","from torch.cuda.amp import autocast, GradScaler\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n","from datasets import load_dataset, load_metric\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21118,"status":"ok","timestamp":1651937147703,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"aF8IWdEowPP-","outputId":"ce780a04-0b10-4a60-f8c6-fa26a96fc89c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Gen RAM Free: 12.1 GB  | Proc size: 812.0 MB\n","GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"]}],"source":["# Check that we are using 100% of GPU memory footprint support libraries/code\n","# from https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip -q install gputil\n","!pip -q install psutil\n","!pip -q install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"]},{"cell_type":"markdown","metadata":{"id":"yoGB7Arrwb4A"},"source":["\n","In case GPU utilisation (Util) is not at 0%, you can uncomment and run the following line to kill all processes to get the full GPU afterwards. Make sure to comment out the line again to not constantly crash the notebook on purpose."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CNdVkubWwdiD"},"outputs":[],"source":["# !kill -9 -1"]},{"cell_type":"markdown","metadata":{"id":"lpKx43Iq6znw"},"source":["## Loading the dataset"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":265,"status":"ok","timestamp":1651937151168,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"kuI6Dv74RU1E","outputId":"efcb5ade-cea4-4a38-f5ba-315ea3a2e76f"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Automatic-Short-Answer-Grading' already exists and is not an empty directory.\n"]}],"source":["# Clone the dataset repository from github\n","!git clone https://github.com/CodyRichter/Automatic-Short-Answer-Grading"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":755,"status":"ok","timestamp":1651937154473,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"P4lofUcJ7nSh","outputId":"8588c5dc-9851-44a0-fa79-557e202f94c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Training Data Responses 16265\n","Number of Test Data (New Answer) Responses 540\n","Number of Test Data (New Question) Responses 733\n","Number of Test Data (New Domain) Responses 4562\n"]}],"source":["import json\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/train.json', 'r') as tf:\n","  training_data = json.load(tf)\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-answers.json', 'r') as tf:\n","  test_unseen_answer_data = json.load(tf)\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-questions.json', 'r') as tf:\n","  test_unseen_question_data = json.load(tf)\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-domains.json', 'r') as tf:\n","  test_unseen_domain_data = json.load(tf)\n","\n","print('Number of Training Data Responses', len(training_data))\n","print('Number of Test Data (New Answer) Responses', len(test_unseen_answer_data))\n","print('Number of Test Data (New Question) Responses', len(test_unseen_question_data))\n","print('Number of Test Data (New Domain) Responses', len(test_unseen_domain_data))"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"umaN_RmJHfxu","executionInfo":{"status":"ok","timestamp":1651937158816,"user_tz":240,"elapsed":138,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","\n","class ShortAnswerGradingDataset(Dataset):\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        # Note: I handle the parsing in the data loading from XML section\n","        # Returns a dict for each item with the following keys: 'question', 'ref', 'response', 'score' all of type 'str'\n","        return self.dataset[idx]"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"0dog0jqL_WEt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651937161289,"user_tz":240,"elapsed":632,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}},"outputId":"fdbaecff-9717-4fe0-9f48-53931f0111e3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Training Samples 12805\n","Number of Validation Samples 1380\n","Number of Test Data (New Answer) Responses 540\n","Number of Test Data (New Question) Responses 733\n","Number of Test Data (New Domain) Responses 4562\n"]}],"source":["training_dataset = ShortAnswerGradingDataset(training_data)\n","test_dataset_unseen_answers = ShortAnswerGradingDataset(test_unseen_answer_data)\n","test_dataset_unseen_questions = ShortAnswerGradingDataset(test_unseen_question_data)\n","test_dataset_unseen_domains = ShortAnswerGradingDataset(test_unseen_domain_data)\n","\n","from sklearn.model_selection import train_test_split\n","\n","training_dataset, validation_dataset = train_test_split(training_dataset, test_size=0.1, random_state=0)\n","\n","validation_parent_ids = set()\n","validation_ids_to_remove = set()\n","validation_original_ids = set()\n","\n","# Step 1: Get IDs of Original Responses and mark augmented ones for deletion\n","for validation_item in validation_dataset:\n","  if validation_item['aug']:\n","    validation_parent_ids.add(validation_item['aug_metadata']['parent_id'])\n","    validation_ids_to_remove.add(validation_item['id'])\n","  else:\n","    validation_original_ids.add(validation_item['id'])\n","\n","train_ids_to_remove = set()\n","\n","# Step 2: Obtain Original Respones for validation set and mark augmented\n","#         dataset items for removal if the original is in the validation set\n","for train_item in training_dataset:\n","\n","  # If the original is in the validation set, remove from the training set\n","  if train_item['aug'] and train_item['aug_metadata']['parent_id'] in validation_original_ids:\n","    train_ids_to_remove.add(train_item['id'])\n","\n","  # If the original is in the training set, add it to the validation set\n","  # and then mark it for deletion from the training set\n","  if not train_item['aug'] and train_item['id'] in validation_parent_ids:\n","    validation_dataset.append(train_item)\n","    train_ids_to_remove.add(train_item['id'])\n","\n","# Step 3: Perform removal operations\n","validation_dataset[:] = [x for x in validation_dataset if x['id'] not in validation_ids_to_remove]\n","training_dataset[:] = [x for x in training_dataset if x['id'] not in train_ids_to_remove]\n","\n","print('Number of Training Samples', len(training_dataset))\n","print('Number of Validation Samples', len(validation_dataset))\n","print('Number of Test Data (New Answer) Responses', len(test_unseen_answer_data))\n","print('Number of Test Data (New Question) Responses', len(test_unseen_question_data))\n","print('Number of Test Data (New Domain) Responses', len(test_unseen_domain_data))"]},{"cell_type":"code","source":["# use the unseen question dataset for testing\n","test_dataset = test_unseen_question_data"],"metadata":{"id":"Y-R6fezZJCaV","executionInfo":{"status":"ok","timestamp":1651937391817,"user_tz":240,"elapsed":100,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140,"status":"ok","timestamp":1651937395783,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"DBwhCI5D_a8I","outputId":"5361388d-4357-4f1b-ef07-452ff1987140"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'question': \"Pam and her family were planning a hike. Pam found 2 maps of the same area. Her friend recommended she use the topographic map when they went to the lake. Why would Pam's friend recommend using the topographic map for the hike?\", 'ref': 'She recommended the topographic map because the map shows the elevations along the trail. Pam would know where the trail was the steepest.', 'response': 'Because both maps show the shapes of landforms, but a topographic map shows elevation and dip.', 'score': 'incorrect', 'aug': True, 'id': 18221, 'aug_metadata': {'parent_id': 3816, 'translation_seq': ['en', 'es', 'en']}}\n","12805\n","733\n"]}],"source":["# for training_item in training_dataset:\n","#   print(training_item)\n","\n","# for test_item in test_dataset:\n","#   print(test_item)\n","print(training_dataset[0])\n","print(len(training_dataset))\n","print(len(test_dataset))"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"Ft72oGmJ_m-c","executionInfo":{"status":"ok","timestamp":1651937549746,"user_tz":240,"elapsed":261,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["# Concate the reference answer and student answer to creat new input for both train and test set\n","train_ref = []\n","train_res = []\n","train_score = []\n","test_ref = []\n","test_res = []\n","test_score = []\n","valid_ref = []\n","valid_res = []\n","valid_score = []\n","\n","for training_item in training_data:\n","  train_ref.append(training_item[\"ref\"])\n","  train_res.append(training_item[\"response\"])\n","  train_score.append(0 if training_item[\"score\"]=='incorrect' else 1)\n","\n","for test_item in test_dataset:\n","  test_ref.append(test_item[\"ref\"])\n","  test_res.append(test_item[\"response\"])\n","  test_score.append(0 if test_item[\"score\"]=='incorrect' else 1)\n","\n","for valid_item in validation_dataset:\n","  valid_ref.append(valid_item[\"ref\"])\n","  valid_res.append(valid_item[\"response\"])\n","  valid_score.append(0 if valid_item[\"score\"]=='incorrect' else 1)\n","\n","train = {'idx': list(range(len(training_data))), 'label': train_score, 'sentence1': train_ref, 'sentence2': train_res}\n","valid = {'idx': list(range(len(validation_dataset))), 'label': valid_score, 'sentence1': valid_ref, 'sentence2': valid_res}\n","test = {'idx': list(range(len(test_dataset))), 'label': test_score, 'sentence1': test_ref, 'sentence2': test_res}\n","\n","# Transform data into pandas dataframes\n","df_train = pd.DataFrame(train)\n","df_valid = pd.DataFrame(valid)\n","df_test = pd.DataFrame(test)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":97,"status":"ok","timestamp":1651937551098,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"nNs2FWNJSLSq","outputId":"50b09ab7-3080-4eb0-f227-8ef540eae6c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["(16265, 4)\n","(1380, 4)\n","(733, 4)\n"]}],"source":["print(df_train.shape)\n","print(df_valid.shape)\n","print(df_test.shape)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":381,"status":"ok","timestamp":1651937582287,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"irj7itV0UCF_","outputId":"ca4f39a9-de09-4938-eb35-6efd515b79ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   idx  label                                          sentence1  \\\n","0    0      0  The water splashed because the fork was vibrat...   \n","1    1      0  The water splashed because the fork was vibrat...   \n","2    2      0  The water splashed because the fork was vibrat...   \n","3    3      0  The water splashed because the fork was vibrat...   \n","4    4      0  The water splashed because the fork was vibrat...   \n","\n","                                         sentence2  \n","0  Hitting the fork and dipping it into the water.  \n","1    Strike the fork and plunge it into the water.  \n","2            Hit the fork and dip it in the water.  \n","3            Hit the fork and immerse it in water.  \n","4        Hit with a fork and submerge it in water.  "],"text/html":["\n","  <div id=\"df-3b68ce12-605c-4c25-b923-d060f82bbbd5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>label</th>\n","      <th>sentence1</th>\n","      <th>sentence2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hitting the fork and dipping it into the water.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Strike the fork and plunge it into the water.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hit the fork and dip it in the water.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hit the fork and immerse it in water.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hit with a fork and submerge it in water.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b68ce12-605c-4c25-b923-d060f82bbbd5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b68ce12-605c-4c25-b923-d060f82bbbd5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b68ce12-605c-4c25-b923-d060f82bbbd5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}],"source":["df_train.head()"]},{"cell_type":"markdown","metadata":{"id":"TWJfh6DV7CB5"},"source":["## Classes and functions"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Tc1GQh7yEm4C","executionInfo":{"status":"ok","timestamp":1651937584379,"user_tz":240,"elapsed":132,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, data, maxlen, with_labels=True, bert_model='bert-base-uncased'):\n","\n","        self.data = data  # pandas dataframe\n","        #Initialize the tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  \n","\n","        self.maxlen = maxlen\n","        self.with_labels = with_labels \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        # Selecting sentence1 and sentence2 at the specified index in the data frame\n","        sent1 = str(self.data.loc[index, 'sentence1'])\n","        sent2 = str(self.data.loc[index, 'sentence2'])\n","\n","        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n","        encoded_pair = self.tokenizer(sent1, sent2, \n","                                      padding='max_length',  # Pad to max_length\n","                                      truncation=True,  # Truncate to max_length\n","                                      max_length=self.maxlen,  \n","                                      return_tensors='pt')  # Return torch.Tensor objects\n","        \n","        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n","        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n","        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n","\n","        if self.with_labels:  # True if the dataset has labels\n","            label = self.data.loc[index, 'label']\n","            return token_ids, attn_masks, token_type_ids, label  \n","        else:\n","            return token_ids, attn_masks, token_type_ids"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"hm0lAXvTZChm","executionInfo":{"status":"ok","timestamp":1651937587967,"user_tz":240,"elapsed":296,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["class SentencePairClassifier(nn.Module):\n","\n","    def __init__(self, bert_model=\"bert-base-uncased\", freeze_bert=False):\n","        super(SentencePairClassifier, self).__init__()\n","        #  Instantiating BERT-based model object\n","        self.bert_layer = AutoModel.from_pretrained(bert_model)\n","\n","        #  Fix the hidden-state size of the encoder outputs (If you want to add other pre-trained models here, search for the encoder output size)\n","        if bert_model == \"albert-base-v2\":  # 12M parameters\n","            hidden_size = 768\n","        elif bert_model == \"albert-large-v2\":  # 18M parameters\n","            hidden_size = 1024\n","        elif bert_model == \"albert-xlarge-v2\":  # 60M parameters\n","            hidden_size = 2048\n","        elif bert_model == \"albert-xxlarge-v2\":  # 235M parameters\n","            hidden_size = 4096\n","        elif bert_model == \"bert-base-uncased\": # 110M parameters\n","            hidden_size = 768\n","        elif bert_model == 'allenai/scibert_scivocab_uncased':\n","            hidden_size = 768\n","\n","        # Freeze bert layers and only train the classification layer weights\n","        if freeze_bert:\n","            for p in self.bert_layer.parameters():\n","                p.requires_grad = False\n","\n","        # Classification layer\n","        self.cls_layer = nn.Linear(hidden_size, 1)\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","    @autocast()  # run in mixed precision\n","    def forward(self, input_ids, attn_masks, token_type_ids):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor  containing token ids\n","            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n","            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n","        '''\n","\n","        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n","        model_output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n","\n","        # Feeding to the classifier layer the last layer hidden-state of the [CLS] token further processed by a\n","        # Linear Layer and a Tanh activation. The Linear layer weights were trained from the sentence order prediction (ALBERT) or next sentence prediction (BERT)\n","        # objective during pre-training.\n","\n","        logits = self.cls_layer(self.dropout(model_output.pooler_output))\n","\n","        return logits"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"5SrSNNYTjwe8","executionInfo":{"status":"ok","timestamp":1651937589970,"user_tz":240,"elapsed":140,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["def set_seed(seed):\n","    \"\"\" Set all seeds to make results reproducible \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","\n","def evaluate_loss(net, device, criterion, dataloader):\n","    net.eval()\n","\n","    mean_loss = 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n","            count += 1\n","\n","    return mean_loss / count"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1651937592502,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"Hl-rhuWsrg01","outputId":"bf34e5a0-846b-4c52-b1c6-5e72eb22854d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creation of the models' folder...\n"]}],"source":["print(\"Creation of the models' folder...\")\n","!mkdir models"]},{"cell_type":"markdown","metadata":{"id":"ZsL9VvmX0NLC"},"source":["Link for mixed precision training, gradient scaling and gradient accumulation  : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n","\n","If you would like to learn more about Training Neural Nets on Larger Batches, I suggest reading this post of Thomas Wolf :\n","https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"I-o6KyaFkU5u","executionInfo":{"status":"ok","timestamp":1651937598685,"user_tz":240,"elapsed":165,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n","\n","    best_loss = np.Inf\n","    best_ep = 1\n","    nb_iterations = len(train_loader)\n","    print_every = nb_iterations // 5  # print the training loss 5 times per epoch\n","    iters = []\n","    train_losses = []\n","    val_losses = []\n","\n","    scaler = GradScaler()\n","\n","    for ep in range(epochs):\n","\n","        net.train()\n","        running_loss = 0.0\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n","\n","            # Converting to cuda tensors\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","    \n","            # Enables autocasting for the forward pass (model + loss)\n","            with autocast():\n","                # Obtaining the logits from the model\n","                logits = net(seq, attn_masks, token_type_ids)\n","\n","                # Computing loss\n","                loss = criterion(logits.squeeze(-1), labels.float())\n","                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n","\n","            # Backpropagating the gradients\n","            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n","            scaler.scale(loss).backward()\n","\n","            if (it + 1) % iters_to_accumulate == 0:\n","                # Optimization step\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n","                # otherwise, opti.step() is skipped.\n","                scaler.step(opti)\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","                # Adjust the learning rate based on the number of iterations.\n","                lr_scheduler.step()\n","                # Clear gradients\n","                opti.zero_grad()\n","\n","\n","            running_loss += loss.item()\n","\n","            if (it + 1) % print_every == 0:  # Print training loss information\n","                print()\n","                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n","                      .format(it+1, nb_iterations, ep+1, running_loss / print_every))\n","\n","                running_loss = 0.0\n","\n","\n","        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n","        print()\n","        print(\"Epoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n","\n","        if val_loss < best_loss:\n","            print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n","            print()\n","            net_copy = copy.deepcopy(net)  # save a copy of the model\n","            best_loss = val_loss\n","            best_ep = ep + 1\n","\n","    # Saving the model\n","    path_to_model='models/{}_lr_{}_val_loss_{}_ep_{}.pt'.format(bert_model.replace('/', '_'), lr, round(best_loss, 5), best_ep)\n","    torch.save(net_copy.state_dict(), path_to_model)\n","    print(\"The model has been saved in {}\".format(path_to_model))\n","\n","    del loss\n","    torch.cuda.empty_cache()"]},{"cell_type":"markdown","metadata":{"id":"WFy9kQ2-SvQ2"},"source":["## Parameters"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"b6bzDp4FreS6","executionInfo":{"status":"ok","timestamp":1651937610921,"user_tz":240,"elapsed":107,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["bert_model = \"bert-base-uncased\"  # 'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2', 'albert-xxlarge-v2', 'bert-base-uncased', ...\n","freeze_bert = True  # if True, freeze the encoder weights and only update the classification layer weights\n","maxlen = 128  # maximum length of the tokenized input sentence pair : if greater than \"maxlen\", the input is truncated and else if smaller, the input is padded\n","bs = 20  # batch size\n","iters_to_accumulate = 2  # the gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate. If set to \"1\", you get the usual batch size\n","lr = 5e-4  # learning rate\n","epochs = 6  # number of training epochs"]},{"cell_type":"markdown","metadata":{"id":"y_abThXlSr6n"},"source":["## Training and validation"]},{"cell_type":"markdown","metadata":{"id":"wwXCoj9_h1hY"},"source":["Link for the AdamW optimizer and the learning rate scheduler :\n","https://huggingface.co/transformers/main_classes/optimizer_schedules.html"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["71403af388124516a99e017694a5a2e3","73e562f2b9e94fc0a1a51a4768c2a335","46ee5aef4b124ad3a8c6056db46d6412","35e572112b6849e7ac92e3f93b7f33f2","c697d68b930346b185641a692279a087","f300825b389b40d18427bbe51fa2c875","68170e2abb40430e924cf5fa48485800","3d080095e7da425fadad4fb034c4b495","544e1625e3f84c3eb7fc7d6bfd1cd691","a5eadcd9274d4fcfb615e87599c3ba9e","7bce58192389494ea009f364155dcd0f","18c3e4d3818049d89dfdd2bd8c14951a","d607c77939e84b4e99ce3080c65e0df3","106824774610476895ec66931a74235d","aa21f51a2b47444fb1486cbcc65dd893","ec9f37fe3dae4c0885789f3d9e10c5f9","0a7721041c00480d959dab2dbd4f3c1b","c61ca9e5a6f34f75abfa079fd428be81","8cb881979bb54ca19470a94bf1291f3c","0722a5cd61e24a6e9af82afcbc0e4367","adf84bd724fc4b289ffc639260c36996","b754f9a43ec141cfb29cfa9ad9771d69","47ea4277b59b4d3ea75a862dd89ca574","4e928f82a5c64d55bf30a63e705dc59e","50fdd4c1c229494886a1a356e0d08456","8201db14e33a40aba891af4bd037a55c","5039d977e4a14c4a843b30b4bce01780","958a11a24984447698892147cc7b614a","58684b3d46a64144a0cda667f4e1f9ae","57e119420eda483c8add9ca2554e5ce4","c4d5aec02fc84e42b1c0dad87d08f118","e708567e8e7144e89d13512d66820871","0d57948de66f418ca113afebb546e87a","a66d5243b79a43108f0c1b94cb930873","8f6e2a48935940e59759cd0298057422","21df56731dfb4642ad5ceab8e37de61b","732ba223d7a8477995f60694d6c857de","66032c8e28c74deba60a56e885cfac8a","81db640936d34fc495ec5d2f8b3b62e0","76a0b55eb5554d45a948128d7f0423fb","ba0495ade2694d00a5bdaed9f95b694d","d63dd283255c4ddd80bf3bd301c2e65b","d2e39d9671914ac6be555375e43098e6","fece375c7974433bbd3819e3b3b6870d","fe9ba9b2eaf64b45a2a1524ebc67c053","f4164b91586f40cdadabef12d477e2cd","230ba43513db4cc59d7dc2555bde56d2","91a70e3d49644e9fab87acf4b28cfdda","a76edca099574274a9b4604863c199a2","9642444372304efa8b27d3c7c6e6b696","872d13dfcdb5434ea3fa92e1751aa053","3de2314b4d754d9dbfc4f54f59882450","944170bd5031490983bb1686e8d91382","b5a2100fcf3b4a8f8712daf2d9435464","afc8ba07a54d48cf84eb6921efe5c0aa"]},"executionInfo":{"elapsed":3394761,"status":"ok","timestamp":1651941008184,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"VZWGPomoryxy","outputId":"0c403a12-f896-40db-b462-32b2e36c38e0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading training data...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71403af388124516a99e017694a5a2e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18c3e4d3818049d89dfdd2bd8c14951a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ea4277b59b4d3ea75a862dd89ca574"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a66d5243b79a43108f0c1b94cb930873"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reading validation data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe9ba9b2eaf64b45a2a1524ebc67c053"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"," 20%|█▉        | 162/814 [01:44<07:05,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 1 complete. Loss : 0.34457021408978805 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 324/814 [03:26<05:09,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 1 complete. Loss : 0.3363598070486828 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 486/814 [05:09<03:27,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 1 complete. Loss : 0.3497038917776979 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 648/814 [06:52<01:45,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 1 complete. Loss : 0.33578661728052445 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 810/814 [08:35<00:02,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 1 complete. Loss : 0.32750997398002646 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [08:37<00:00,  1.57it/s]\n","100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 complete! Validation Loss : 0.6457539243974547\n","Best validation loss improved from inf to 0.6457539243974547\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 162/814 [01:43<06:55,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 2 complete. Loss : 0.3271299749612808 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 324/814 [03:26<05:11,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 2 complete. Loss : 0.3288746094906036 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 486/814 [05:09<03:27,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 2 complete. Loss : 0.34727350291278625 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 648/814 [06:51<01:44,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 2 complete. Loss : 0.33325429499885184 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 810/814 [08:34<00:02,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 2 complete. Loss : 0.3245023613174756 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [08:36<00:00,  1.58it/s]\n","100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2 complete! Validation Loss : 0.6447747747103373\n","Best validation loss improved from 0.6457539243974547 to 0.6447747747103373\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 162/814 [01:43<06:52,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 3 complete. Loss : 0.3230298173464375 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 324/814 [03:25<05:10,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 3 complete. Loss : 0.32308817098354115 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 486/814 [05:08<03:27,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 3 complete. Loss : 0.3429439869927771 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 648/814 [06:51<01:44,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 3 complete. Loss : 0.3303739782652737 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 810/814 [08:33<00:02,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 3 complete. Loss : 0.32133904559376797 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [08:35<00:00,  1.58it/s]\n","100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3 complete! Validation Loss : 0.649357159068619\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 162/814 [01:43<06:51,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 4 complete. Loss : 0.31714567703045443 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 324/814 [03:25<05:11,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 4 complete. Loss : 0.32014736551561473 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 486/814 [05:08<03:27,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 4 complete. Loss : 0.340092367320149 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 648/814 [06:51<01:45,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 4 complete. Loss : 0.33096000818926613 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 810/814 [08:34<00:02,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 4 complete. Loss : 0.32088476171096164 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [08:36<00:00,  1.58it/s]\n","100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4 complete! Validation Loss : 0.650379238785177\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 162/814 [01:43<06:54,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 5 complete. Loss : 0.31090507803507794 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 324/814 [03:25<05:12,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 5 complete. Loss : 0.32056083456601625 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 486/814 [05:08<03:27,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 5 complete. Loss : 0.3361194944124163 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 648/814 [06:51<01:45,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 5 complete. Loss : 0.3293644031624735 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 810/814 [08:33<00:02,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 5 complete. Loss : 0.3208422498018653 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [08:36<00:00,  1.58it/s]\n","100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 5 complete! Validation Loss : 0.643730424452519\n","Best validation loss improved from 0.6447747747103373 to 0.643730424452519\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 162/814 [01:43<06:53,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 6 complete. Loss : 0.30954350048193224 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 324/814 [03:25<05:10,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 6 complete. Loss : 0.3264164560370975 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 486/814 [05:08<03:26,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 6 complete. Loss : 0.32792718966066103 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 648/814 [06:51<01:47,  1.55it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 6 complete. Loss : 0.3274201743396712 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 810/814 [08:34<00:02,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 6 complete. Loss : 0.3193566015473119 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [08:36<00:00,  1.57it/s]\n","100%|██████████| 69/69 [00:43<00:00,  1.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 6 complete! Validation Loss : 0.6352263546508291\n","Best validation loss improved from 0.643730424452519 to 0.6352263546508291\n","\n","The model has been saved in models/bert-base-uncased_lr_0.0005_val_loss_0.63523_ep_6.pt\n"]}],"source":["#  Set all seeds to make reproducible results\n","set_seed(1)\n","\n","# Creating instances of training and validation set\n","print(\"Reading training data...\")\n","train_set = CustomDataset(df_train, maxlen, bert_model)\n","print(\"Reading validation data...\")\n","val_set = CustomDataset(df_valid, maxlen, bert_model)\n","# Creating instances of training and validation dataloaders\n","train_loader = DataLoader(train_set, batch_size=bs, num_workers=5)\n","val_loader = DataLoader(val_set, batch_size=bs, num_workers=5)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = SentencePairClassifier(bert_model, freeze_bert=freeze_bert)\n","\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    net = nn.DataParallel(net)\n","\n","net.to(device)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","num_training_steps = epochs * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * epochs  # Necessary to take into account Gradient accumulation\n","lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","\n","train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)"]},{"cell_type":"markdown","metadata":{"id":"gw2sOrIvCEZz"},"source":["You can download the model saved in the folder \"models\" by browsing the files on the left of the colab notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_f4zThMtvqC1"},"outputs":[],"source":["# If you encounter a CUDA out of memory error: \n","# - uncomment the kill command, run the \"kill\" command (and comment it)\n","# - reduce the batch size\n","# - then run all cells from the begining \n","\n","# !kill -9 -1"]},{"cell_type":"markdown","metadata":{"id":"nDBtVu7JSbUK"},"source":["## Prediction"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1651941021323,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"kAfbt0FjkCfM","outputId":"cb7792f5-44d0-4ffc-b1a9-c6f0e81cb173"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creation of the results' folder...\n"]}],"source":["print(\"Creation of the results' folder...\")\n","!mkdir results"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"m3r8_npVf30D","executionInfo":{"status":"ok","timestamp":1651941023122,"user_tz":240,"elapsed":182,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"}}},"outputs":[],"source":["def get_probs_from_logits(logits):\n","    \"\"\"\n","    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n","    \"\"\"\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    return probs.detach().cpu().numpy()\n","\n","def test_prediction(net, device, dataloader, with_labels=True, result_file=\"results/output.txt\"):\n","    \"\"\"\n","    Predict the probabilities on a dataset with or without labels and print the result in a file\n","    \"\"\"\n","    net.eval()\n","    w = open(result_file, 'w')\n","    probs_all = []\n","\n","    with torch.no_grad():\n","        if with_labels:\n","            for seq, attn_masks, token_type_ids, _ in tqdm(dataloader):\n","                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","                logits = net(seq, attn_masks, token_type_ids)\n","                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","                probs_all += probs.tolist()\n","        else:\n","            for seq, attn_masks, token_type_ids in tqdm(dataloader):\n","                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","                logits = net(seq, attn_masks, token_type_ids)\n","                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","                probs_all += probs.tolist()\n","\n","    w.writelines(str(prob)+'\\n' for prob in probs_all)\n","    w.close()"]},{"cell_type":"markdown","metadata":{"id":"5-VJObbxwL6r"},"source":["I'm sharing below an ALBERT pre-trained model (45 Mo) so you can reproduce my results on the MRPC validation set (**91.19** as F1 score and **87.5** as accuracy). It's just in case but if all the code run as expected, you should get after the model training the correct model in the *models* folder\n","\n","You can download it and upload it (~ 3 minutes) in the *models* folder by browsing the files on the left of the colab notebook :\n","\n","https://drive.google.com/file/d/1AcRLGvALAH3BVSiDVjY_b8CggJgVfksp/view?usp=sharing"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31794,"status":"ok","timestamp":1651941063670,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"xWoWiw6MlPm-","outputId":"6ef4147d-8223-4b39-a83b-827d2903fab7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading test data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n","Loading the weights of the model...\n","Predicting on test data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 37/37 [00:23<00:00,  1.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Predictions are available in : results/output.txt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["path_to_model = '/content/models/bert-base-uncased_lr_0.0005_val_loss_0.63523_ep_6.pt'  \n","# path_to_model = '/content/models/...'  # You can add here your trained model\n","\n","path_to_output_file = 'results/output.txt'\n","\n","print(\"Reading test data...\")\n","test_set = CustomDataset(df_test, maxlen, bert_model)\n","test_loader = DataLoader(test_set, batch_size=bs, num_workers=5)\n","\n","model = SentencePairClassifier(bert_model)\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    model = nn.DataParallel(model)\n","\n","print()\n","print(\"Loading the weights of the model...\")\n","model.load_state_dict(torch.load(path_to_model))\n","model.to(device)\n","\n","print(\"Predicting on test data...\")\n","test_prediction(net=model, device=device, dataloader=test_loader, with_labels=True,  # set the with_labels parameter to False if your want to get predictions on a dataset without labels\n","                result_file=path_to_output_file)\n","print()\n","print(\"Predictions are available in : {}\".format(path_to_output_file))"]},{"cell_type":"markdown","metadata":{"id":"HCVAtClcC1qT"},"source":["You can download the predictions saved in the folder \"results\" by browsing the files on the left of the colab notebook"]},{"cell_type":"markdown","metadata":{"id":"Ywxq1c8DSiV3"},"source":["## Evaluation"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["cb7cf33c05ad4a45bffa5b210192f8fe","4d3c6cffb0bf49dfb5d44b490f6554b1","5456c5af454f442f8f25b415eb249572","8e15b1358578487fa1af2dbfae36110d","f93c79082c4e4225ac82f331a2503a39","ee03a4d7d0a8400280ac7d4dea5af039","9aa0a27d41534616a281fa2327c5e357","947d6ee1c3704161aa013a1f03eee85f","595a5b2544b449a1ab37072fb44c3ea6","f6a2052bb8df4abab80d6446d0afdef2","8f1c00155c5547559e6cbaf07aeb52a5"]},"executionInfo":{"elapsed":661,"status":"ok","timestamp":1651941066903,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"6JYwEPtrlBFX","outputId":"1b97e29d-d7eb-4180-8209-d7bbcbd935ab"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb7cf33c05ad4a45bffa5b210192f8fe"}},"metadata":{}}],"source":["path_to_output_file = 'results/output.txt'  # path to the file with prediction probabilities\n","\n","labels_test = df_test['label']  # true labels\n","\n","probs_test = pd.read_csv(path_to_output_file, header=None)[0]  # prediction probabilities\n","\n","threshold = 0.5   # you can adjust this threshold for your own dataset\n","preds_test=(probs_test>=threshold).astype('uint8') # predicted labels using the above fixed threshold\n","\n","metric = load_metric(\"glue\", \"mrpc\")"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1651941069161,"user":{"displayName":"Dat Duong","userId":"04669328169947431173"},"user_tz":240},"id":"G3ReQL2CUj3I","outputId":"a32d1f0d-fc90-4b49-b53e-1ef8cbe2d0a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.5798090040927695, 'f1': 0.5157232704402516}"]},"metadata":{},"execution_count":30}],"source":["# Compute the accuracy and F1 scores\n","metric._compute(predictions=preds_test, references=labels_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vyr7WxvYk-NC"},"outputs":[],"source":["# Result -----\n","\n","# bert_model = \"bert-base-uncased\" \n","# freeze_bert = True\n","# maxlen = 128 \n","# bs = 20\n","# iters_to_accumulate = 2 \n","# lr = 1e-3  \n","# epochs = 4\n","# test dataset: Unseen questions\n","# accuracy = 0.68\n","\n","# bert_model = \"bert-base-uncased\" \n","# freeze_bert = True\n","# maxlen = 128 \n","# bs = 20\n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 6\n","# test dataset: Unseen questions\n","# accuracy = 0.52\n","\n","\n","# Augmented data\n","#------------------\n","# bert_model = \"bert-base-uncased\" \n","# freeze_bert = True\n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 10 \n","# test dataset: Unseen questions\n","# accuracy = 0.64\n","# f1 0.617\n","\n","# bert_model = \"bert-base-uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 15 \n","# test dataset: Unseen questions\n","# accuracy = 0.66\n","# f1 0.65\n","\n","# bert_model = \"bert-base-uncased\" \n","# freeze_bert = True\n","# maxlen = 128 \n","# bs = 20\n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 6\n","# test dataset: Unseen questions\n","# accuracy = 0.65\n","# f1 = 0.615\n","\n","\n","# -------------------------\n","# new new augmented dataset\n","\n","# bert_model = \"bert-base-uncased\" \n","# freeze_bert = True\n","# maxlen = 128 \n","# bs = 20\n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 6\n","# test dataset: Unseen questions\n","# accuracy = 0.5798\n","# f1 = 0.515"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"fine_tune_bert.ipynb","provenance":[{"file_id":"1sa0z0yKWSiNuRlnh4w4Wv2CII9JP71QT","timestamp":1651706524885},{"file_id":"https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb","timestamp":1651010185319}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"71403af388124516a99e017694a5a2e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73e562f2b9e94fc0a1a51a4768c2a335","IPY_MODEL_46ee5aef4b124ad3a8c6056db46d6412","IPY_MODEL_35e572112b6849e7ac92e3f93b7f33f2"],"layout":"IPY_MODEL_c697d68b930346b185641a692279a087"}},"73e562f2b9e94fc0a1a51a4768c2a335":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f300825b389b40d18427bbe51fa2c875","placeholder":"​","style":"IPY_MODEL_68170e2abb40430e924cf5fa48485800","value":"Downloading: 100%"}},"46ee5aef4b124ad3a8c6056db46d6412":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d080095e7da425fadad4fb034c4b495","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_544e1625e3f84c3eb7fc7d6bfd1cd691","value":28}},"35e572112b6849e7ac92e3f93b7f33f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5eadcd9274d4fcfb615e87599c3ba9e","placeholder":"​","style":"IPY_MODEL_7bce58192389494ea009f364155dcd0f","value":" 28.0/28.0 [00:00&lt;00:00, 500B/s]"}},"c697d68b930346b185641a692279a087":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f300825b389b40d18427bbe51fa2c875":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68170e2abb40430e924cf5fa48485800":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d080095e7da425fadad4fb034c4b495":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"544e1625e3f84c3eb7fc7d6bfd1cd691":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a5eadcd9274d4fcfb615e87599c3ba9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bce58192389494ea009f364155dcd0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18c3e4d3818049d89dfdd2bd8c14951a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d607c77939e84b4e99ce3080c65e0df3","IPY_MODEL_106824774610476895ec66931a74235d","IPY_MODEL_aa21f51a2b47444fb1486cbcc65dd893"],"layout":"IPY_MODEL_ec9f37fe3dae4c0885789f3d9e10c5f9"}},"d607c77939e84b4e99ce3080c65e0df3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a7721041c00480d959dab2dbd4f3c1b","placeholder":"​","style":"IPY_MODEL_c61ca9e5a6f34f75abfa079fd428be81","value":"Downloading: 100%"}},"106824774610476895ec66931a74235d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cb881979bb54ca19470a94bf1291f3c","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0722a5cd61e24a6e9af82afcbc0e4367","value":570}},"aa21f51a2b47444fb1486cbcc65dd893":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_adf84bd724fc4b289ffc639260c36996","placeholder":"​","style":"IPY_MODEL_b754f9a43ec141cfb29cfa9ad9771d69","value":" 570/570 [00:00&lt;00:00, 9.90kB/s]"}},"ec9f37fe3dae4c0885789f3d9e10c5f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a7721041c00480d959dab2dbd4f3c1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c61ca9e5a6f34f75abfa079fd428be81":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cb881979bb54ca19470a94bf1291f3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0722a5cd61e24a6e9af82afcbc0e4367":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"adf84bd724fc4b289ffc639260c36996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b754f9a43ec141cfb29cfa9ad9771d69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47ea4277b59b4d3ea75a862dd89ca574":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e928f82a5c64d55bf30a63e705dc59e","IPY_MODEL_50fdd4c1c229494886a1a356e0d08456","IPY_MODEL_8201db14e33a40aba891af4bd037a55c"],"layout":"IPY_MODEL_5039d977e4a14c4a843b30b4bce01780"}},"4e928f82a5c64d55bf30a63e705dc59e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_958a11a24984447698892147cc7b614a","placeholder":"​","style":"IPY_MODEL_58684b3d46a64144a0cda667f4e1f9ae","value":"Downloading: 100%"}},"50fdd4c1c229494886a1a356e0d08456":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e119420eda483c8add9ca2554e5ce4","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c4d5aec02fc84e42b1c0dad87d08f118","value":231508}},"8201db14e33a40aba891af4bd037a55c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e708567e8e7144e89d13512d66820871","placeholder":"​","style":"IPY_MODEL_0d57948de66f418ca113afebb546e87a","value":" 226k/226k [00:00&lt;00:00, 1.61MB/s]"}},"5039d977e4a14c4a843b30b4bce01780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"958a11a24984447698892147cc7b614a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58684b3d46a64144a0cda667f4e1f9ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"57e119420eda483c8add9ca2554e5ce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4d5aec02fc84e42b1c0dad87d08f118":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e708567e8e7144e89d13512d66820871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d57948de66f418ca113afebb546e87a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a66d5243b79a43108f0c1b94cb930873":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8f6e2a48935940e59759cd0298057422","IPY_MODEL_21df56731dfb4642ad5ceab8e37de61b","IPY_MODEL_732ba223d7a8477995f60694d6c857de"],"layout":"IPY_MODEL_66032c8e28c74deba60a56e885cfac8a"}},"8f6e2a48935940e59759cd0298057422":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81db640936d34fc495ec5d2f8b3b62e0","placeholder":"​","style":"IPY_MODEL_76a0b55eb5554d45a948128d7f0423fb","value":"Downloading: 100%"}},"21df56731dfb4642ad5ceab8e37de61b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba0495ade2694d00a5bdaed9f95b694d","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d63dd283255c4ddd80bf3bd301c2e65b","value":466062}},"732ba223d7a8477995f60694d6c857de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2e39d9671914ac6be555375e43098e6","placeholder":"​","style":"IPY_MODEL_fece375c7974433bbd3819e3b3b6870d","value":" 455k/455k [00:00&lt;00:00, 1.51MB/s]"}},"66032c8e28c74deba60a56e885cfac8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81db640936d34fc495ec5d2f8b3b62e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76a0b55eb5554d45a948128d7f0423fb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba0495ade2694d00a5bdaed9f95b694d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d63dd283255c4ddd80bf3bd301c2e65b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2e39d9671914ac6be555375e43098e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fece375c7974433bbd3819e3b3b6870d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe9ba9b2eaf64b45a2a1524ebc67c053":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f4164b91586f40cdadabef12d477e2cd","IPY_MODEL_230ba43513db4cc59d7dc2555bde56d2","IPY_MODEL_91a70e3d49644e9fab87acf4b28cfdda"],"layout":"IPY_MODEL_a76edca099574274a9b4604863c199a2"}},"f4164b91586f40cdadabef12d477e2cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9642444372304efa8b27d3c7c6e6b696","placeholder":"​","style":"IPY_MODEL_872d13dfcdb5434ea3fa92e1751aa053","value":"Downloading: 100%"}},"230ba43513db4cc59d7dc2555bde56d2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3de2314b4d754d9dbfc4f54f59882450","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_944170bd5031490983bb1686e8d91382","value":440473133}},"91a70e3d49644e9fab87acf4b28cfdda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5a2100fcf3b4a8f8712daf2d9435464","placeholder":"​","style":"IPY_MODEL_afc8ba07a54d48cf84eb6921efe5c0aa","value":" 420M/420M [00:14&lt;00:00, 37.0MB/s]"}},"a76edca099574274a9b4604863c199a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9642444372304efa8b27d3c7c6e6b696":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872d13dfcdb5434ea3fa92e1751aa053":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3de2314b4d754d9dbfc4f54f59882450":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"944170bd5031490983bb1686e8d91382":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5a2100fcf3b4a8f8712daf2d9435464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afc8ba07a54d48cf84eb6921efe5c0aa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb7cf33c05ad4a45bffa5b210192f8fe":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d3c6cffb0bf49dfb5d44b490f6554b1","IPY_MODEL_5456c5af454f442f8f25b415eb249572","IPY_MODEL_8e15b1358578487fa1af2dbfae36110d"],"layout":"IPY_MODEL_f93c79082c4e4225ac82f331a2503a39"}},"4d3c6cffb0bf49dfb5d44b490f6554b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee03a4d7d0a8400280ac7d4dea5af039","placeholder":"​","style":"IPY_MODEL_9aa0a27d41534616a281fa2327c5e357","value":"Downloading builder script: "}},"5456c5af454f442f8f25b415eb249572":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_947d6ee1c3704161aa013a1f03eee85f","max":1844,"min":0,"orientation":"horizontal","style":"IPY_MODEL_595a5b2544b449a1ab37072fb44c3ea6","value":1844}},"8e15b1358578487fa1af2dbfae36110d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a2052bb8df4abab80d6446d0afdef2","placeholder":"​","style":"IPY_MODEL_8f1c00155c5547559e6cbaf07aeb52a5","value":" 5.76k/? [00:00&lt;00:00, 138kB/s]"}},"f93c79082c4e4225ac82f331a2503a39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee03a4d7d0a8400280ac7d4dea5af039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9aa0a27d41534616a281fa2327c5e357":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"947d6ee1c3704161aa013a1f03eee85f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"595a5b2544b449a1ab37072fb44c3ea6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f6a2052bb8df4abab80d6446d0afdef2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f1c00155c5547559e6cbaf07aeb52a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}