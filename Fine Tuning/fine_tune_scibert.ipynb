{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"fine_tune_scibert.ipynb","provenance":[{"file_id":"https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb","timestamp":1651010185319}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"03852317f2754888841e36aed1acad53":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_80027e3a54a9493d9e10c1db7c6b99ce","IPY_MODEL_2e39371f888d4c70a592802a28d96e77","IPY_MODEL_e76a87b482704478bbf5d5414e2265c9"],"layout":"IPY_MODEL_d2c7c13eb7f049bc832c1e0cab4686c4"}},"80027e3a54a9493d9e10c1db7c6b99ce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d4d6b1dad6c4fe99911d034815bb23f","placeholder":"​","style":"IPY_MODEL_83c034e6b3594af0885ecea8aefe4a8a","value":"Downloading: 100%"}},"2e39371f888d4c70a592802a28d96e77":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c676d5fe61e84c369031e379af5e985a","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07d0bc33b11046849085e527ee26aac7","value":28}},"e76a87b482704478bbf5d5414e2265c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c2dba0d2f6348b0b6ff29e92cdf97a1","placeholder":"​","style":"IPY_MODEL_1639f6d72bdf48128b5064467df7fdda","value":" 28.0/28.0 [00:00&lt;00:00, 824B/s]"}},"d2c7c13eb7f049bc832c1e0cab4686c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d4d6b1dad6c4fe99911d034815bb23f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83c034e6b3594af0885ecea8aefe4a8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c676d5fe61e84c369031e379af5e985a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07d0bc33b11046849085e527ee26aac7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c2dba0d2f6348b0b6ff29e92cdf97a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1639f6d72bdf48128b5064467df7fdda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"437bfc20383144f397b449a5738219c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_094997f7029b4afeaed7496db2e5d988","IPY_MODEL_c83da3a59f5f44568389a0ca462af72f","IPY_MODEL_214a707ca94a4db2aa8427da481ffefd"],"layout":"IPY_MODEL_f7b51742cd9f4b33898471fcb25c541c"}},"094997f7029b4afeaed7496db2e5d988":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06b8db5e9db84997a651b529bbfca511","placeholder":"​","style":"IPY_MODEL_3b371f017d9b4545920ffe5c907a9a06","value":"Downloading: 100%"}},"c83da3a59f5f44568389a0ca462af72f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a47c324683f4355a934dfa9d660b5b8","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c285a4c725844225b8f8bb6062235b15","value":570}},"214a707ca94a4db2aa8427da481ffefd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c5370fed22a4469846c815d310208dc","placeholder":"​","style":"IPY_MODEL_f657cdd03a24478199fda45c10b97548","value":" 570/570 [00:00&lt;00:00, 7.15kB/s]"}},"f7b51742cd9f4b33898471fcb25c541c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06b8db5e9db84997a651b529bbfca511":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b371f017d9b4545920ffe5c907a9a06":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a47c324683f4355a934dfa9d660b5b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c285a4c725844225b8f8bb6062235b15":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4c5370fed22a4469846c815d310208dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f657cdd03a24478199fda45c10b97548":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9523c31969be41bcb565fc514c48f3ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e578a33bbf2e4148a3b4cd03708fce2f","IPY_MODEL_613a53d7773140a780c1d0d50dd0cd00","IPY_MODEL_3e0cca5731c146159337cac4b22fca4b"],"layout":"IPY_MODEL_2c90b3e9dd9b4b3b96db98eaa3650c38"}},"e578a33bbf2e4148a3b4cd03708fce2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd3a1b5fe54a42f6ae1ff599e94d9648","placeholder":"​","style":"IPY_MODEL_9c8b00ec79c54bd19437ef6210f55209","value":"Downloading: 100%"}},"613a53d7773140a780c1d0d50dd0cd00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5f40f829b974bb5ac5aeaac07beaadd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4edf1a8709f140f4a1764feb810a899b","value":231508}},"3e0cca5731c146159337cac4b22fca4b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_48a1350084014a90a8901c142bea6878","placeholder":"​","style":"IPY_MODEL_e2dfdf6674c94044940326e97a2076b3","value":" 226k/226k [00:00&lt;00:00, 263kB/s]"}},"2c90b3e9dd9b4b3b96db98eaa3650c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd3a1b5fe54a42f6ae1ff599e94d9648":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c8b00ec79c54bd19437ef6210f55209":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5f40f829b974bb5ac5aeaac07beaadd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4edf1a8709f140f4a1764feb810a899b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"48a1350084014a90a8901c142bea6878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2dfdf6674c94044940326e97a2076b3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97892d1b986f432a98478ec608db11f1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d42c2980d1ba4ecc84552ca569bb25f2","IPY_MODEL_5b7ee407eb574f66a0706b25ebe1bb35","IPY_MODEL_6fa46679c59d483b97756a507b1018bb"],"layout":"IPY_MODEL_434eebfa8ff740378a492f3ef25b970f"}},"d42c2980d1ba4ecc84552ca569bb25f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d7ee917b3c54f91b08ece9ec21d4456","placeholder":"​","style":"IPY_MODEL_0e6399d0e2904c058e790662d136f340","value":"Downloading: 100%"}},"5b7ee407eb574f66a0706b25ebe1bb35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba8f372c1fb2457d9ff4739137dcd1e6","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e96ae1dc1eda4956a9ccb19a9045e784","value":466062}},"6fa46679c59d483b97756a507b1018bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cc0d1dbb2124057ba1ca00d3d51cd09","placeholder":"​","style":"IPY_MODEL_52f6c3dde9444b2786c87559a785031a","value":" 455k/455k [00:00&lt;00:00, 625kB/s]"}},"434eebfa8ff740378a492f3ef25b970f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d7ee917b3c54f91b08ece9ec21d4456":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e6399d0e2904c058e790662d136f340":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba8f372c1fb2457d9ff4739137dcd1e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e96ae1dc1eda4956a9ccb19a9045e784":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cc0d1dbb2124057ba1ca00d3d51cd09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52f6c3dde9444b2786c87559a785031a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5a80256b0b246518179493d05cf19b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_720599a1f1944333a525a37b33a3c10b","IPY_MODEL_1750d5bd68d44dbc9793ae8c7cffac9a","IPY_MODEL_a56c583ea4714a2ba341ae8ce59b2d6b"],"layout":"IPY_MODEL_78ede4cbc0204cd4955966f82c29eddc"}},"720599a1f1944333a525a37b33a3c10b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7174834239f149809ccd8e365a703db6","placeholder":"​","style":"IPY_MODEL_456a6396fafb465e94d59cd8dd9e06c3","value":"Downloading: 100%"}},"1750d5bd68d44dbc9793ae8c7cffac9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8aaa4b27d2494624a50f7c6c4041a30a","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ddf42f9797ef4e2e9fd38a585cc31ea9","value":440473133}},"a56c583ea4714a2ba341ae8ce59b2d6b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ebe7e3e5a524a5299725bde01086080","placeholder":"​","style":"IPY_MODEL_7ee5cc4656974ce4acc7289623c7a879","value":" 420M/420M [00:07&lt;00:00, 53.4MB/s]"}},"78ede4cbc0204cd4955966f82c29eddc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7174834239f149809ccd8e365a703db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"456a6396fafb465e94d59cd8dd9e06c3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8aaa4b27d2494624a50f7c6c4041a30a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddf42f9797ef4e2e9fd38a585cc31ea9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0ebe7e3e5a524a5299725bde01086080":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ee5cc4656974ce4acc7289623c7a879":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec63627abc554363b17823ed93beb64d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61d065d185c044b5abee355567cdf8ef","IPY_MODEL_129ddc5e11fb4d68bc94967c360e71ba","IPY_MODEL_714480b7428f473ead87b5bc8a83342d"],"layout":"IPY_MODEL_b19885f34adf489db3127fbeedfcce4b"}},"61d065d185c044b5abee355567cdf8ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9713405aea574f09bf67d6c442e85a18","placeholder":"​","style":"IPY_MODEL_31db9afaa386435d9a43b940add9a4e5","value":"Downloading builder script: "}},"129ddc5e11fb4d68bc94967c360e71ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2010d462a75482586092d6da894e68f","max":1844,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6c28b85a1994a2180fdd911d32a3890","value":1844}},"714480b7428f473ead87b5bc8a83342d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f7115586ab841bb836cdac6fd0f20d0","placeholder":"​","style":"IPY_MODEL_59c3c6cf807b475888e0cc81826861d2","value":" 5.76k/? [00:00&lt;00:00, 177kB/s]"}},"b19885f34adf489db3127fbeedfcce4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9713405aea574f09bf67d6c442e85a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31db9afaa386435d9a43b940add9a4e5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f2010d462a75482586092d6da894e68f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6c28b85a1994a2180fdd911d32a3890":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8f7115586ab841bb836cdac6fd0f20d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59c3c6cf807b475888e0cc81826861d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb#scrollTo=xtkcmIY9t6AF"],"metadata":{"id":"pvdhFnb44b4J"}},{"cell_type":"markdown","metadata":{"id":"YIv7rF4V6lyE"},"source":["## Installation of libraries and imports"]},{"cell_type":"code","metadata":{"id":"42-lJ1u9IHT6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652123219127,"user_tz":240,"elapsed":17168,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"dceab447-1808-44b7-fbaf-7deab7d5adf6"},"source":["!pip install transformers\n","!pip install datasets"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","\u001b[K     |████████████████████████████████| 4.0 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 50.8 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 7.8 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n","\u001b[K     |████████████████████████████████| 880 kB 55.7 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 65.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=18ac908d5f8eb7df93374230e9d1bd0eb02355366d7824a8e9b8b1ee55bf447b\n","  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n","Successfully built sacremoses\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n","Collecting datasets\n","  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n","\u001b[K     |████████████████████████████████| 325 kB 4.1 MB/s \n","\u001b[?25hCollecting aiohttp\n","  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Collecting fsspec[http]>=2021.05.0\n","  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n","\u001b[K     |████████████████████████████████| 136 kB 73.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Collecting xxhash\n","  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[K     |████████████████████████████████| 212 kB 63.2 MB/s \n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n","Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 74.0 MB/s \n","\u001b[?25hCollecting asynctest==0.13.0\n","  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[K     |████████████████████████████████| 144 kB 66.2 MB/s \n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n","\u001b[K     |████████████████████████████████| 94 kB 4.2 MB/s \n","\u001b[?25hCollecting yarl<2.0,>=1.0\n","  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n","\u001b[K     |████████████████████████████████| 271 kB 57.7 MB/s \n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"]}]},{"cell_type":"code","metadata":{"id":"KE_TpNaSZQ5n"},"source":["import torch\n","import torch.nn as nn\n","import os\n","import matplotlib.pyplot as plt\n","import copy\n","import torch.optim as optim\n","import random\n","import numpy as np\n","import pandas as pd\n","import glob\n","import xml.etree.ElementTree as ET\n","from torch.utils.data import DataLoader, Dataset\n","from torch.cuda.amp import autocast, GradScaler\n","from tqdm import tqdm\n","from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n","from datasets import load_dataset, load_metric\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aF8IWdEowPP-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c1b903c-9818-4ef8-a66c-ff63c988fb1d","executionInfo":{"status":"ok","timestamp":1652123242238,"user_tz":240,"elapsed":16583,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}}},"source":["# Check that we are using 100% of GPU memory footprint support libraries/code\n","# from https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb\n","!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n","!pip -q install gputil\n","!pip -q install psutil\n","!pip -q install humanize\n","import psutil\n","import humanize\n","import os\n","import GPUtil as GPU\n","GPUs = GPU.getGPUs()\n","# XXX: only one GPU on Colab and isn’t guaranteed\n","gpu = GPUs[0]\n","def printm():\n"," process = psutil.Process(os.getpid())\n"," print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n"," print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n","printm()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Gen RAM Free: 12.1 GB  | Proc size: 810.2 MB\n","GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"]}]},{"cell_type":"markdown","metadata":{"id":"yoGB7Arrwb4A"},"source":["\n","In case GPU utilisation (Util) is not at 0%, you can uncomment and run the following line to kill all processes to get the full GPU afterwards. Make sure to comment out the line again to not constantly crash the notebook on purpose."]},{"cell_type":"code","metadata":{"id":"CNdVkubWwdiD"},"source":["# !kill -9 -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lpKx43Iq6znw"},"source":["## Loading the dataset"]},{"cell_type":"code","source":["# Clone the dataset repository from github\n","# Clone the dataset repository from github\n","!git clone https://github.com/CodyRichter/Automatic-Short-Answer-Grading"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuI6Dv74RU1E","executionInfo":{"status":"ok","timestamp":1652123243909,"user_tz":240,"elapsed":1689,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"6a203fd5-361c-43dd-f2cf-76bf925e99a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Automatic-Short-Answer-Grading'...\n","remote: Enumerating objects: 33, done.\u001b[K\n","remote: Counting objects: 100% (33/33), done.\u001b[K\n","remote: Compressing objects: 100% (20/20), done.\u001b[K\n","remote: Total 33 (delta 12), reused 23 (delta 8), pack-reused 0\u001b[K\n","Unpacking objects: 100% (33/33), done.\n"]}]},{"cell_type":"code","source":["import json\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/train.json', 'r') as tf:\n","  training_data = json.load(tf)\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-answers.json', 'r') as tf:\n","  test_unseen_answer_data = json.load(tf)\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-questions.json', 'r') as tf:\n","  test_unseen_question_data = json.load(tf)\n","\n","with open('/content/Automatic-Short-Answer-Grading/dataset/test-unseen-domains.json', 'r') as tf:\n","  test_unseen_domain_data = json.load(tf)\n","\n","print('Number of Training + Validation Data Responses', len(training_data))"],"metadata":{"id":"P4lofUcJ7nSh","executionInfo":{"status":"ok","timestamp":1652123244195,"user_tz":240,"elapsed":292,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8ea4f280-2b19-4e63-d9d6-03018419d702"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Training + Validation Data Responses 16265\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class ShortAnswerGradingDataset(Dataset):\n","    def __init__(self, dataset):\n","        self.dataset = dataset\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        # Note: I handle the parsing in the data loading from XML section\n","        # Returns a dict for each item with the following keys: 'question', 'ref', 'response', 'score' all of type 'str'\n","        return self.dataset[idx]"],"metadata":{"id":"CpXksqbD0Ol8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["training_dataset = ShortAnswerGradingDataset(training_data)\n","test_dataset_unseen_answers = ShortAnswerGradingDataset(test_unseen_answer_data)\n","test_dataset_unseen_questions = ShortAnswerGradingDataset(test_unseen_question_data)\n","test_dataset_unseen_domains = ShortAnswerGradingDataset(test_unseen_domain_data)\n","\n","from sklearn.model_selection import train_test_split\n","\n","training_dataset, validation_dataset = train_test_split(training_dataset, test_size=0.1, random_state=0)\n","\n","validation_parent_ids = set()\n","validation_ids_to_remove = set()\n","validation_original_ids = set()\n","\n","# Step 1: Get IDs of Original Responses and mark augmented ones for deletion\n","for validation_item in validation_dataset:\n","  if validation_item['aug']:\n","    validation_parent_ids.add(validation_item['aug_metadata']['parent_id'])\n","    validation_ids_to_remove.add(validation_item['id'])\n","  else:\n","    validation_original_ids.add(validation_item['id'])\n","\n","train_ids_to_remove = set()\n","\n","# Step 2: Obtain Original Respones for validation set and mark augmented\n","#         dataset items for removal if the original is in the validation set\n","for train_item in training_dataset:\n","\n","  # If the original is in the validation set, remove from the training set\n","  if train_item['aug'] and train_item['aug_metadata']['parent_id'] in validation_original_ids:\n","    train_ids_to_remove.add(train_item['id'])\n","\n","  # If the original is in the training set, add it to the validation set\n","  # and then mark it for deletion from the training set\n","  if not train_item['aug'] and train_item['id'] in validation_parent_ids:\n","    validation_dataset.append(train_item)\n","    train_ids_to_remove.add(train_item['id'])\n","\n","# Step 3: Perform removal operations\n","validation_dataset[:] = [x for x in validation_dataset if x['id'] not in validation_ids_to_remove]\n","training_dataset[:] = [x for x in training_dataset if x['id'] not in train_ids_to_remove]"],"metadata":{"id":"tF6KmjIr0TjR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Number of Training Samples', len(training_dataset))\n","print('Number of Validation Samples', len(validation_dataset))\n","print('Number of Test Data (New Answer) Responses', len(test_unseen_answer_data))\n","print('Number of Test Data (New Question) Responses', len(test_unseen_question_data))\n","print('Number of Test Data (New Domain) Responses', len(test_unseen_domain_data))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sZYXtQh10XGV","executionInfo":{"status":"ok","timestamp":1652123244619,"user_tz":240,"elapsed":36,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"3945ebbf-ff7e-4a14-bf61-9204253e8ed1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of Training Samples 12805\n","Number of Validation Samples 1380\n","Number of Test Data (New Answer) Responses 540\n","Number of Test Data (New Question) Responses 733\n","Number of Test Data (New Domain) Responses 4562\n"]}]},{"cell_type":"code","source":["# use the unseen question dataset for testing\n","test_dataset = test_unseen_question_data"],"metadata":{"id":"0dog0jqL_WEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for training_item in training_dataset:\n","#   print(training_item)\n","\n","# for test_item in test_dataset:\n","#   print(test_item)\n","print(training_dataset[0])\n","print(len(training_dataset))\n","print(len(test_dataset))"],"metadata":{"id":"DBwhCI5D_a8I","executionInfo":{"status":"ok","timestamp":1652123244620,"user_tz":240,"elapsed":33,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b252320-8520-4c06-a818-6422a2bd4527"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'question': \"Pam and her family were planning a hike. Pam found 2 maps of the same area. Her friend recommended she use the topographic map when they went to the lake. Why would Pam's friend recommend using the topographic map for the hike?\", 'ref': 'She recommended the topographic map because the map shows the elevations along the trail. Pam would know where the trail was the steepest.', 'response': 'Because both maps show the shapes of landforms, but a topographic map shows elevation and dip.', 'score': 'incorrect', 'aug': True, 'id': 18221, 'aug_metadata': {'parent_id': 3816, 'translation_seq': ['en', 'es', 'en']}}\n","12805\n","733\n"]}]},{"cell_type":"code","source":["# Concate the reference answer and student answer to creat new input for both train and test set\n","train_ref = []\n","train_res = []\n","train_score = []\n","test_ref = []\n","test_res = []\n","test_score = []\n","valid_ref = []\n","valid_res = []\n","valid_score = []\n","\n","for training_item in training_data:\n","  train_ref.append(training_item[\"ref\"])\n","  train_res.append(training_item[\"response\"])\n","  train_score.append(0 if training_item[\"score\"]=='incorrect' else 1)\n","\n","for test_item in test_dataset:\n","  test_ref.append(test_item[\"ref\"])\n","  test_res.append(test_item[\"response\"])\n","  test_score.append(0 if test_item[\"score\"]=='incorrect' else 1)\n","\n","for valid_item in validation_dataset:\n","  valid_ref.append(valid_item[\"ref\"])\n","  valid_res.append(valid_item[\"response\"])\n","  valid_score.append(0 if valid_item[\"score\"]=='incorrect' else 1)\n","\n","train = {'idx': list(range(len(training_data))), 'label': train_score, 'sentence1': train_ref, 'sentence2': train_res}\n","valid = {'idx': list(range(len(validation_dataset))), 'label': valid_score, 'sentence1': valid_ref, 'sentence2': valid_res}\n","test = {'idx': list(range(len(test_dataset))), 'label': test_score, 'sentence1': test_ref, 'sentence2': test_res}\n","\n","# Transform data into pandas dataframes\n","df_train = pd.DataFrame(train)\n","df_valid = pd.DataFrame(valid)\n","df_test = pd.DataFrame(test)"],"metadata":{"id":"_RZ_D8qN1AB_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# # dateset split for the dataset with no validation split\n","# # Concate the reference answer and student answer to creat new input for both train and test set\n","# number_test = 100\n","# train_ref = []\n","# train_res = []\n","# train_score = []\n","# test_ref = []\n","# test_res = []\n","# test_score = []\n","\n","# for training_item in training_data:\n","#   train_ref.append(training_item[\"ref\"])\n","#   train_res.append(training_item[\"response\"])\n","#   train_score.append(0 if training_item[\"score\"]=='incorrect' else 1)\n","\n","# train = {'idx': list(range(len(training_data))), 'label': train_score, 'sentence1': train_ref, 'sentence2': train_res}\n","\n","# for test_item in test_dataset:\n","#   test_ref.append(test_item[\"ref\"])\n","#   test_res.append(test_item[\"response\"])\n","#   test_score.append(0 if test_item[\"score\"]=='incorrect' else 1)\n","\n","# valid = {'idx': list(range(number_test,len( test_dataset))), 'label': test_score[number_test:], 'sentence1': test_ref[number_test:], 'sentence2': test_res[number_test:]}\n","# test = {'idx': list(range(number_test)), 'label': test_score[0:number_test], 'sentence1': test_ref[0:number_test], 'sentence2': test_res[0:number_test]}\n","\n","# # Transform data into pandas dataframes\n","# df_train = pd.DataFrame(train)\n","# df_valid = pd.DataFrame(valid)\n","# df_test = pd.DataFrame(test)"],"metadata":{"id":"Ft72oGmJ_m-c"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNs2FWNJSLSq","executionInfo":{"status":"ok","timestamp":1652123244621,"user_tz":240,"elapsed":29,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b86095e-a769-4b74-adc9-05860a8681f0"},"source":["print(df_train.shape)\n","print(df_valid.shape)\n","print(df_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(16265, 4)\n","(1380, 4)\n","(733, 4)\n"]}]},{"cell_type":"code","metadata":{"id":"irj7itV0UCF_","executionInfo":{"status":"ok","timestamp":1652123244622,"user_tz":240,"elapsed":27,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"604deb1c-767b-4399-f750-ce234bf3c528"},"source":["df_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   idx  label                                          sentence1  \\\n","0    0      0  The water splashed because the fork was vibrat...   \n","1    1      0  The water splashed because the fork was vibrat...   \n","2    2      0  The water splashed because the fork was vibrat...   \n","3    3      0  The water splashed because the fork was vibrat...   \n","4    4      0  The water splashed because the fork was vibrat...   \n","\n","                                         sentence2  \n","0  Hitting the fork and dipping it into the water.  \n","1    Strike the fork and plunge it into the water.  \n","2            Hit the fork and dip it in the water.  \n","3            Hit the fork and immerse it in water.  \n","4        Hit with a fork and submerge it in water.  "],"text/html":["\n","  <div id=\"df-4272613c-1e57-464a-bed5-bc4cdb655803\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>idx</th>\n","      <th>label</th>\n","      <th>sentence1</th>\n","      <th>sentence2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hitting the fork and dipping it into the water.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Strike the fork and plunge it into the water.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hit the fork and dip it in the water.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hit the fork and immerse it in water.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>The water splashed because the fork was vibrat...</td>\n","      <td>Hit with a fork and submerge it in water.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4272613c-1e57-464a-bed5-bc4cdb655803')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4272613c-1e57-464a-bed5-bc4cdb655803 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4272613c-1e57-464a-bed5-bc4cdb655803');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"TWJfh6DV7CB5"},"source":["## Classes and functions"]},{"cell_type":"code","metadata":{"id":"Tc1GQh7yEm4C"},"source":["class CustomDataset(Dataset):\n","\n","    def __init__(self, data, maxlen, with_labels=True, bert_model='bert-base-uncased'):\n","\n","        self.data = data  # pandas dataframe\n","        #Initialize the tokenizer\n","        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  \n","\n","        self.maxlen = maxlen\n","        self.with_labels = with_labels \n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","\n","        # Selecting sentence1 and sentence2 at the specified index in the data frame\n","        sent1 = str(self.data.loc[index, 'sentence1'])\n","        sent2 = str(self.data.loc[index, 'sentence2'])\n","\n","        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n","        encoded_pair = self.tokenizer(sent1, sent2, \n","                                      padding='max_length',  # Pad to max_length\n","                                      truncation=True,  # Truncate to max_length\n","                                      max_length=self.maxlen,  \n","                                      return_tensors='pt')  # Return torch.Tensor objects\n","        \n","        token_ids = encoded_pair['input_ids'].squeeze(0)  # tensor of token ids\n","        attn_masks = encoded_pair['attention_mask'].squeeze(0)  # binary tensor with \"0\" for padded values and \"1\" for the other values\n","        token_type_ids = encoded_pair['token_type_ids'].squeeze(0)  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n","\n","        if self.with_labels:  # True if the dataset has labels\n","            label = self.data.loc[index, 'label']\n","            return token_ids, attn_masks, token_type_ids, label  \n","        else:\n","            return token_ids, attn_masks, token_type_ids"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hm0lAXvTZChm"},"source":["class SentencePairClassifier(nn.Module):\n","\n","    def __init__(self, bert_model=\"bert-base-uncased\", freeze_bert=False):\n","        super(SentencePairClassifier, self).__init__()\n","        #  Instantiating BERT-based model object\n","        self.bert_layer = AutoModel.from_pretrained(bert_model)\n","\n","        #  Fix the hidden-state size of the encoder outputs (If you want to add other pre-trained models here, search for the encoder output size)\n","        if bert_model == \"albert-base-v2\":  # 12M parameters\n","            hidden_size = 768\n","        elif bert_model == \"albert-large-v2\":  # 18M parameters\n","            hidden_size = 1024\n","        elif bert_model == \"albert-xlarge-v2\":  # 60M parameters\n","            hidden_size = 2048\n","        elif bert_model == \"albert-xxlarge-v2\":  # 235M parameters\n","            hidden_size = 4096\n","        elif bert_model == \"bert-base-uncased\": # 110M parameters\n","            hidden_size = 768\n","        elif bert_model == 'allenai/scibert_scivocab_uncased':\n","            hidden_size = 768\n","\n","        # Freeze bert layers and only train the classification layer weights\n","        if freeze_bert:\n","            for p in self.bert_layer.parameters():\n","                p.requires_grad = False\n","\n","        # Classification layer\n","        self.cls_layer = nn.Linear(hidden_size, 1)\n","\n","        self.dropout = nn.Dropout(p=0.1)\n","\n","    @autocast()  # run in mixed precision\n","    def forward(self, input_ids, attn_masks, token_type_ids):\n","        '''\n","        Inputs:\n","            -input_ids : Tensor  containing token ids\n","            -attn_masks : Tensor containing attention masks to be used to focus on non-padded values\n","            -token_type_ids : Tensor containing token type ids to be used to identify sentence1 and sentence2\n","        '''\n","\n","        # Feeding the inputs to the BERT-based model to obtain contextualized representations\n","        model_output = self.bert_layer(input_ids, attn_masks, token_type_ids)\n","\n","        # Feeding to the classifier layer the last layer hidden-state of the [CLS] token further processed by a\n","        # Linear Layer and a Tanh activation. The Linear layer weights were trained from the sentence order prediction (ALBERT) or next sentence prediction (BERT)\n","        # objective during pre-training.\n","\n","        logits = self.cls_layer(self.dropout(model_output.pooler_output))\n","\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SrSNNYTjwe8"},"source":["def set_seed(seed):\n","    \"\"\" Set all seeds to make results reproducible \"\"\"\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    \n","\n","def evaluate_loss(net, device, criterion, dataloader):\n","    net.eval()\n","\n","    mean_loss = 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(dataloader)):\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","            logits = net(seq, attn_masks, token_type_ids)\n","            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n","            count += 1\n","\n","    return mean_loss / count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hl-rhuWsrg01","executionInfo":{"status":"ok","timestamp":1652123244906,"user_tz":240,"elapsed":308,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d0eef04-ce2e-4832-9c59-ae031e12265f"},"source":["print(\"Creation of the models' folder...\")\n","!mkdir models"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creation of the models' folder...\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZsL9VvmX0NLC"},"source":["Link for mixed precision training, gradient scaling and gradient accumulation  : https://pytorch.org/docs/stable/notes/amp_examples.html#amp-examples\n","\n","If you would like to learn more about Training Neural Nets on Larger Batches, I suggest reading this post of Thomas Wolf :\n","https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255"]},{"cell_type":"code","metadata":{"id":"I-o6KyaFkU5u"},"source":["def train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate):\n","\n","    best_loss = np.Inf\n","    best_ep = 1\n","    nb_iterations = len(train_loader)\n","    print_every = nb_iterations // 5  # print the training loss 5 times per epoch\n","    iters = []\n","    train_losses = []\n","    val_losses = []\n","\n","    scaler = GradScaler()\n","\n","    for ep in range(epochs):\n","\n","        net.train()\n","        running_loss = 0.0\n","        for it, (seq, attn_masks, token_type_ids, labels) in enumerate(tqdm(train_loader)):\n","\n","            # Converting to cuda tensors\n","            seq, attn_masks, token_type_ids, labels = \\\n","                seq.to(device), attn_masks.to(device), token_type_ids.to(device), labels.to(device)\n","    \n","            # Enables autocasting for the forward pass (model + loss)\n","            with autocast():\n","                # Obtaining the logits from the model\n","                logits = net(seq, attn_masks, token_type_ids)\n","\n","                # Computing loss\n","                loss = criterion(logits.squeeze(-1), labels.float())\n","                loss = loss / iters_to_accumulate  # Normalize the loss because it is averaged\n","\n","            # Backpropagating the gradients\n","            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n","            scaler.scale(loss).backward()\n","\n","            if (it + 1) % iters_to_accumulate == 0:\n","                # Optimization step\n","                # scaler.step() first unscales the gradients of the optimizer's assigned params.\n","                # If these gradients do not contain infs or NaNs, opti.step() is then called,\n","                # otherwise, opti.step() is skipped.\n","                scaler.step(opti)\n","                # Updates the scale for next iteration.\n","                scaler.update()\n","                # Adjust the learning rate based on the number of iterations.\n","                lr_scheduler.step()\n","                # Clear gradients\n","                opti.zero_grad()\n","\n","\n","            running_loss += loss.item()\n","\n","            if (it + 1) % print_every == 0:  # Print training loss information\n","                print()\n","                print(\"Iteration {}/{} of epoch {} complete. Loss : {} \"\n","                      .format(it+1, nb_iterations, ep+1, running_loss / print_every))\n","\n","                running_loss = 0.0\n","\n","\n","        val_loss = evaluate_loss(net, device, criterion, val_loader)  # Compute validation loss\n","        print()\n","        print(\"Epoch {} complete! Validation Loss : {}\".format(ep+1, val_loss))\n","\n","        if val_loss < best_loss:\n","            print(\"Best validation loss improved from {} to {}\".format(best_loss, val_loss))\n","            print()\n","            net_copy = copy.deepcopy(net)  # save a copy of the model\n","            best_loss = val_loss\n","            best_ep = ep + 1\n","\n","    # Saving the model\n","    path_to_model='models/{}_lr_{}_val_loss_{}_ep_{}.pt'.format(bert_model.replace('/', '_'), lr, round(best_loss, 5), best_ep)\n","    torch.save(net_copy.state_dict(), path_to_model)\n","    print(\"The model has been saved in {}\".format(path_to_model))\n","\n","    del loss\n","    torch.cuda.empty_cache()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WFy9kQ2-SvQ2"},"source":["## Parameters"]},{"cell_type":"code","metadata":{"id":"b6bzDp4FreS6"},"source":["bert_model = \"bert-base-uncased\"  # 'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2', 'albert-xxlarge-v2', 'bert-base-uncased', allenai/scibert_scivocab_uncased ...\n","freeze_bert = True  # if True, freeze the encoder weights and only update the classification layer weights\n","maxlen = 128  # maximum length of the tokenized input sentence pair : if greater than \"maxlen\", the input is truncated and else if smaller, the input is padded\n","bs = 20  # batch size\n","iters_to_accumulate = 2  # the gradient accumulation adds gradients over an effective batch of size : bs * iters_to_accumulate. If set to \"1\", you get the usual batch size\n","lr = 5e-4  # learning rate\n","epochs = 6  # number of training epochs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y_abThXlSr6n"},"source":["## Training and validation"]},{"cell_type":"markdown","metadata":{"id":"wwXCoj9_h1hY"},"source":["Link for the AdamW optimizer and the learning rate scheduler :\n","https://huggingface.co/transformers/main_classes/optimizer_schedules.html"]},{"cell_type":"code","metadata":{"id":"VZWGPomoryxy","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["03852317f2754888841e36aed1acad53","80027e3a54a9493d9e10c1db7c6b99ce","2e39371f888d4c70a592802a28d96e77","e76a87b482704478bbf5d5414e2265c9","d2c7c13eb7f049bc832c1e0cab4686c4","6d4d6b1dad6c4fe99911d034815bb23f","83c034e6b3594af0885ecea8aefe4a8a","c676d5fe61e84c369031e379af5e985a","07d0bc33b11046849085e527ee26aac7","9c2dba0d2f6348b0b6ff29e92cdf97a1","1639f6d72bdf48128b5064467df7fdda","437bfc20383144f397b449a5738219c7","094997f7029b4afeaed7496db2e5d988","c83da3a59f5f44568389a0ca462af72f","214a707ca94a4db2aa8427da481ffefd","f7b51742cd9f4b33898471fcb25c541c","06b8db5e9db84997a651b529bbfca511","3b371f017d9b4545920ffe5c907a9a06","6a47c324683f4355a934dfa9d660b5b8","c285a4c725844225b8f8bb6062235b15","4c5370fed22a4469846c815d310208dc","f657cdd03a24478199fda45c10b97548","9523c31969be41bcb565fc514c48f3ce","e578a33bbf2e4148a3b4cd03708fce2f","613a53d7773140a780c1d0d50dd0cd00","3e0cca5731c146159337cac4b22fca4b","2c90b3e9dd9b4b3b96db98eaa3650c38","dd3a1b5fe54a42f6ae1ff599e94d9648","9c8b00ec79c54bd19437ef6210f55209","d5f40f829b974bb5ac5aeaac07beaadd","4edf1a8709f140f4a1764feb810a899b","48a1350084014a90a8901c142bea6878","e2dfdf6674c94044940326e97a2076b3","97892d1b986f432a98478ec608db11f1","d42c2980d1ba4ecc84552ca569bb25f2","5b7ee407eb574f66a0706b25ebe1bb35","6fa46679c59d483b97756a507b1018bb","434eebfa8ff740378a492f3ef25b970f","7d7ee917b3c54f91b08ece9ec21d4456","0e6399d0e2904c058e790662d136f340","ba8f372c1fb2457d9ff4739137dcd1e6","e96ae1dc1eda4956a9ccb19a9045e784","1cc0d1dbb2124057ba1ca00d3d51cd09","52f6c3dde9444b2786c87559a785031a","c5a80256b0b246518179493d05cf19b5","720599a1f1944333a525a37b33a3c10b","1750d5bd68d44dbc9793ae8c7cffac9a","a56c583ea4714a2ba341ae8ce59b2d6b","78ede4cbc0204cd4955966f82c29eddc","7174834239f149809ccd8e365a703db6","456a6396fafb465e94d59cd8dd9e06c3","8aaa4b27d2494624a50f7c6c4041a30a","ddf42f9797ef4e2e9fd38a585cc31ea9","0ebe7e3e5a524a5299725bde01086080","7ee5cc4656974ce4acc7289623c7a879"]},"outputId":"85214425-ae94-4943-880f-016ed80a25d2","executionInfo":{"status":"ok","timestamp":1652123749621,"user_tz":240,"elapsed":504721,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}}},"source":["#  Set all seeds to make reproducible results\n","set_seed(1)\n","\n","# Creating instances of training and validation set\n","print(\"Reading training data...\")\n","train_set = CustomDataset(df_train, maxlen, bert_model)\n","print(\"Reading validation data...\")\n","val_set = CustomDataset(df_valid, maxlen, bert_model)\n","# Creating instances of training and validation dataloaders\n","train_loader = DataLoader(train_set, batch_size=bs, num_workers=5)\n","val_loader = DataLoader(val_set, batch_size=bs, num_workers=5)\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = SentencePairClassifier(bert_model, freeze_bert=freeze_bert)\n","\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    net = nn.DataParallel(net)\n","\n","net.to(device)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","opti = AdamW(net.parameters(), lr=lr, weight_decay=1e-2)\n","num_warmup_steps = 0 # The number of steps for the warmup phase.\n","num_training_steps = epochs * len(train_loader)  # The total number of training steps\n","t_total = (len(train_loader) // iters_to_accumulate) * epochs  # Necessary to take into account Gradient accumulation\n","lr_scheduler = get_linear_schedule_with_warmup(optimizer=opti, num_warmup_steps=num_warmup_steps, num_training_steps=t_total)\n","\n","train_bert(net, criterion, opti, lr, lr_scheduler, train_loader, val_loader, epochs, iters_to_accumulate)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading training data...\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03852317f2754888841e36aed1acad53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"437bfc20383144f397b449a5738219c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9523c31969be41bcb565fc514c48f3ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97892d1b986f432a98478ec608db11f1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reading validation data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5a80256b0b246518179493d05cf19b5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"," 20%|██        | 163/814 [00:14<00:56, 11.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 1 complete. Loss : 0.34559095917660515 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 325/814 [00:28<00:42, 11.57it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 1 complete. Loss : 0.33602750586506763 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 487/814 [00:42<00:28, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 1 complete. Loss : 0.34941604834647827 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 649/814 [00:56<00:14, 11.55it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 1 complete. Loss : 0.33524783866273034 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 811/814 [01:10<00:00, 11.69it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 1 complete. Loss : 0.3267639212218332 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [01:10<00:00, 11.51it/s]\n","100%|██████████| 69/69 [00:06<00:00, 11.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1 complete! Validation Loss : 0.64827152006868\n","Best validation loss improved from inf to 0.64827152006868\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 163/814 [00:14<00:56, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 2 complete. Loss : 0.32838631536305685 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 325/814 [00:28<00:42, 11.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 2 complete. Loss : 0.32755142261768566 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 487/814 [00:42<00:28, 11.60it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 2 complete. Loss : 0.3474337097579314 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 649/814 [00:56<00:14, 11.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 2 complete. Loss : 0.3330878723918656 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 811/814 [01:10<00:00, 11.69it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 2 complete. Loss : 0.3248633550089083 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [01:10<00:00, 11.56it/s]\n","100%|██████████| 69/69 [00:06<00:00, 11.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 2 complete! Validation Loss : 0.6448148324869681\n","Best validation loss improved from 0.64827152006868 to 0.6448148324869681\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 163/814 [00:14<00:56, 11.51it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 3 complete. Loss : 0.32349399900362813 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 325/814 [00:28<00:41, 11.66it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 3 complete. Loss : 0.32337575359844867 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 487/814 [00:42<00:28, 11.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 3 complete. Loss : 0.34310859634920404 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 649/814 [00:56<00:14, 11.55it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 3 complete. Loss : 0.33206148509993966 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 811/814 [01:10<00:00, 11.71it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 3 complete. Loss : 0.3218651254787857 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [01:10<00:00, 11.56it/s]\n","100%|██████████| 69/69 [00:06<00:00, 11.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 3 complete! Validation Loss : 0.6494582813719044\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 163/814 [00:14<00:56, 11.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 4 complete. Loss : 0.31653720379611594 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 325/814 [00:28<00:42, 11.61it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 4 complete. Loss : 0.32012961593307093 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 487/814 [00:42<00:28, 11.62it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 4 complete. Loss : 0.339455064892033 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 649/814 [00:56<00:14, 11.61it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 4 complete. Loss : 0.32890460621795536 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 811/814 [01:10<00:00, 11.63it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 4 complete. Loss : 0.3205661389194889 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [01:10<00:00, 11.56it/s]\n","100%|██████████| 69/69 [00:06<00:00, 11.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 4 complete! Validation Loss : 0.6540530557217805\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 163/814 [00:14<00:56, 11.53it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 5 complete. Loss : 0.3121989375371256 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 325/814 [00:28<00:42, 11.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 5 complete. Loss : 0.3213370148966342 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 487/814 [00:42<00:28, 11.49it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 5 complete. Loss : 0.33458446315777157 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 649/814 [00:56<00:14, 11.29it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 5 complete. Loss : 0.3278001203765104 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 811/814 [01:10<00:00, 11.70it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 5 complete. Loss : 0.31773306686937075 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [01:10<00:00, 11.53it/s]\n","100%|██████████| 69/69 [00:06<00:00, 11.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 5 complete! Validation Loss : 0.6427880214608234\n","Best validation loss improved from 0.6448148324869681 to 0.6427880214608234\n","\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 163/814 [00:14<00:56, 11.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 162/814 of epoch 6 complete. Loss : 0.3090433695434052 \n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 325/814 [00:28<00:42, 11.46it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 324/814 of epoch 6 complete. Loss : 0.3274050849823304 \n"]},{"output_type":"stream","name":"stderr","text":[" 60%|█████▉    | 487/814 [00:42<00:28, 11.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 486/814 of epoch 6 complete. Loss : 0.32709041817320716 \n"]},{"output_type":"stream","name":"stderr","text":[" 80%|███████▉  | 649/814 [00:56<00:14, 11.52it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 648/814 of epoch 6 complete. Loss : 0.32932890086998173 \n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████▉| 811/814 [01:10<00:00, 11.59it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Iteration 810/814 of epoch 6 complete. Loss : 0.3176518041226599 \n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 814/814 [01:10<00:00, 11.53it/s]\n","100%|██████████| 69/69 [00:06<00:00, 11.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Epoch 6 complete! Validation Loss : 0.6351056807283042\n","Best validation loss improved from 0.6427880214608234 to 0.6351056807283042\n","\n","The model has been saved in models/bert-base-uncased_lr_0.0005_val_loss_0.63511_ep_6.pt\n"]}]},{"cell_type":"markdown","metadata":{"id":"gw2sOrIvCEZz"},"source":["You can download the model saved in the folder \"models\" by browsing the files on the left of the colab notebook"]},{"cell_type":"code","metadata":{"id":"_f4zThMtvqC1"},"source":["# If you encounter a CUDA out of memory error: \n","# - uncomment the kill command, run the \"kill\" command (and comment it)\n","# - reduce the batch size\n","# - then run all cells from the begining \n","\n","# !kill -9 -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nDBtVu7JSbUK"},"source":["## Prediction"]},{"cell_type":"code","metadata":{"id":"kAfbt0FjkCfM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652123749622,"user_tz":240,"elapsed":13,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"8a21d384-e9bc-45b3-89b1-55fcfc0aac56"},"source":["print(\"Creation of the results' folder...\")\n","!mkdir results"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creation of the results' folder...\n"]}]},{"cell_type":"code","metadata":{"id":"m3r8_npVf30D"},"source":["def get_probs_from_logits(logits):\n","    \"\"\"\n","    Converts a tensor of logits into an array of probabilities by applying the sigmoid function\n","    \"\"\"\n","    probs = torch.sigmoid(logits.unsqueeze(-1))\n","    return probs.detach().cpu().numpy()\n","\n","def test_prediction(net, device, dataloader, with_labels=True, result_file=\"results/output.txt\"):\n","    \"\"\"\n","    Predict the probabilities on a dataset with or without labels and print the result in a file\n","    \"\"\"\n","    net.eval()\n","    w = open(result_file, 'w')\n","    probs_all = []\n","\n","    with torch.no_grad():\n","        if with_labels:\n","            for seq, attn_masks, token_type_ids, _ in tqdm(dataloader):\n","                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","                logits = net(seq, attn_masks, token_type_ids)\n","                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","                probs_all += probs.tolist()\n","        else:\n","            for seq, attn_masks, token_type_ids in tqdm(dataloader):\n","                seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n","                logits = net(seq, attn_masks, token_type_ids)\n","                probs = get_probs_from_logits(logits.squeeze(-1)).squeeze(-1)\n","                probs_all += probs.tolist()\n","\n","    w.writelines(str(prob)+'\\n' for prob in probs_all)\n","    w.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xWoWiw6MlPm-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1652124187431,"user_tz":240,"elapsed":14877,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"9e7cce72-8b35-4fd4-b3a3-3239dec27603"},"source":["path_to_model = '/content/models/bert-base-uncased_lr_0.0005_val_loss_0.63511_ep_6.pt' \n","# path_to_model = '/content/models/...'  # Add the new model trained to eval\n","\n","path_to_output_file = 'results/output.txt'\n","\n","print(\"Reading test data...\")\n","test_set = CustomDataset(df_test, maxlen, bert_model)\n","test_loader = DataLoader(test_set, batch_size=bs, num_workers=5)\n","\n","model = SentencePairClassifier(bert_model)\n","if torch.cuda.device_count() > 1:  # if multiple GPUs\n","    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n","    model = nn.DataParallel(model)\n","\n","print()\n","print(\"Loading the weights of the model...\")\n","model.load_state_dict(torch.load(path_to_model))\n","model.to(device)\n","\n","print(\"Predicting on test data...\")\n","test_prediction(net=model, device=device, dataloader=test_loader, with_labels=True,  # set the with_labels parameter to False if your want to get predictions on a dataset without labels\n","                result_file=path_to_output_file)\n","print()\n","print(\"Predictions are available in : {}\".format(path_to_output_file))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading test data...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["\n","Loading the weights of the model...\n","Predicting on test data...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 37/37 [00:03<00:00, 10.48it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Predictions are available in : results/output.txt\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"HCVAtClcC1qT"},"source":["You can download the predictions saved in the folder \"results\" by browsing the files on the left of the colab notebook"]},{"cell_type":"markdown","metadata":{"id":"Ywxq1c8DSiV3"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"6JYwEPtrlBFX"},"source":["path_to_output_file = 'results/output.txt'  # path to the file with prediction probabilities\n","\n","labels_test = df_test['label']  # true labels\n","\n","probs_test = pd.read_csv(path_to_output_file, header=None)[0]  # prediction probabilities"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G3ReQL2CUj3I","colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["ec63627abc554363b17823ed93beb64d","61d065d185c044b5abee355567cdf8ef","129ddc5e11fb4d68bc94967c360e71ba","714480b7428f473ead87b5bc8a83342d","b19885f34adf489db3127fbeedfcce4b","9713405aea574f09bf67d6c442e85a18","31db9afaa386435d9a43b940add9a4e5","f2010d462a75482586092d6da894e68f","a6c28b85a1994a2180fdd911d32a3890","8f7115586ab841bb836cdac6fd0f20d0","59c3c6cf807b475888e0cc81826861d2"]},"executionInfo":{"status":"ok","timestamp":1652124194756,"user_tz":240,"elapsed":1753,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"0cac5d4b-a9a1-4b3b-cf2b-c171ba18bb6e"},"source":["threshold = 0.5\n","preds_test=(probs_test>=threshold).astype('uint8')\n","metric = load_metric(\"glue\", \"mrpc\")\n","metric._compute(predictions=preds_test, references=labels_test)\n","#mrpc\n","# threshold 0.46\n","# {'accuracy': 0.6480218281036835, 'f1': 0.5742574257425742}"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec63627abc554363b17823ed93beb64d"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'accuracy': 0.5784447476125512, 'f1': 0.5118483412322274}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["print(metric.inputs_description)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"neOtlLyU5hJj","executionInfo":{"status":"ok","timestamp":1652127536812,"user_tz":240,"elapsed":303,"user":{"displayName":"Peilan Wang","userId":"03253077972159635505"}},"outputId":"957fc65d-79a7-444f-f55e-bb3ab8f8b0d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Compute GLUE evaluation metric associated to each GLUE dataset.\n","Args:\n","    predictions: list of predictions to score.\n","        Each translation should be tokenized into a list of tokens.\n","    references: list of lists of references for each translation.\n","        Each reference should be tokenized into a list of tokens.\n","Returns: depending on the GLUE subset, one or several of:\n","    \"accuracy\": Accuracy\n","    \"f1\": F1 score\n","    \"pearson\": Pearson Correlation\n","    \"spearmanr\": Spearman Correlation\n","    \"matthews_correlation\": Matthew Correlation\n","Examples:\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'accuracy': 1.0, 'f1': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n","    >>> references = [0., 1., 2., 3., 4., 5.]\n","    >>> predictions = [0., 1., 2., 3., 4., 5.]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n","    {'pearson': 1.0, 'spearmanr': 1.0}\n","\n","    >>> glue_metric = datasets.load_metric('glue', 'cola')\n","    >>> references = [0, 1]\n","    >>> predictions = [0, 1]\n","    >>> results = glue_metric.compute(predictions=predictions, references=references)\n","    >>> print(results)\n","    {'matthews_correlation': 1.0}\n","\n"]}]},{"cell_type":"code","source":["# Result -----\n","\n","# After 15 epochs the validation stopped improving\n","# Above were dataset without augmented data\n","\n","# -------------------------------------------------------\n","# bert_model = \"allenai/scibert_scivocab_uncased\" \n","# freeze_bert = False \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 3 \n","# test dataset: Unseen questions\n","# accuracy = 0.5893587994542974\n","\n","# bert_model = \"allenai/scibert_scivocab_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 6 \n","# test dataset: Unseen questions\n","# accuracy = 0.6002728512960437\n","\n","# bert_model = \"allenai/scibert_scivocab_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 15 \n","# test dataset: Unseen questions\n","# accuracy = 0.645293315143247\n","#---------------------------------------------------------\n","# More data from back translation\n","# bert_model = \"allenai/scibert_scivocab_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 6 \n","# test dataset: Unseen questions\n","# accuracy = 0.6193724420190996\n","\n","# bert_model = \"allenai/scibert_scivocab_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 1e-3  \n","# epochs = 6 \n","# test dataset: Unseen questions\n","# {'accuracy': 0.6330150068212824, 'f1': 0.48565965583174} \n","\n","# bert_model = \"allenai/scibert_scivocab_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 15 \n","# test dataset: Unseen questions\n","# accuracy = 0.6507503410641201\n","\n","# bert_model = \"bert_base_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 6 \n","# test dataset: Unseen questions\n","# accuracy = 0.5866302864938608\n","\n","# bert_model = \"bert_base_uncased\" \n","# freeze_bert = True \n","# maxlen = 128 \n","# bs = 20 \n","# iters_to_accumulate = 2 \n","# lr = 5e-4  \n","# epochs = 15 \n","# test dataset: Unseen questions\n","# accuracy = 0.5757162346521146\n"],"metadata":{"id":"vyr7WxvYk-NC"},"execution_count":null,"outputs":[]}]}